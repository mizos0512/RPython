{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # PANDAS\n",
    "  'Pandas' es un estándar de la industria para analizar datos en Python. Con unas pocas pulsaciones de teclas, puedes cargar, filtrar, reestructurar y visualizar gigabytes de información heterogénea. Está desarrollado sobre la biblioteca 'NumPy' y toma prestados muchos de sus conceptos y convenciones de sintaxis, por lo que si te sientes cómodo con 'NumPy', Pandas te resultará una herramienta bastante familiar. E incluso si nunca has oído hablar de 'NumPy', Pandas ofrece una gran oportunidad para resolver problemas de análisis de datos con poca o ninguna experiencia en programación.\n",
    "\n",
    "Dos características clave que Pandas aporta a las matrices 'NumPy' son:\n",
    "\n",
    "1. Tipos heterogéneos: cada columna puede tener su propio tipo;\n",
    "\n",
    "2. Índice: mejora la velocidad de búsqueda de las columnas especificadas.\n",
    "\n",
    "Resulta que estas características son suficientes para hacer de 'Pandas' un poderoso competidor tanto de las 'hojas de cálculo' como de las 'bases de datos'.\n",
    "\n",
    "'Polars', la reciente reencarnación de Pandas (escrita en 'Rust', por lo tanto más rápida ¹) ya no usa 'NumPy' bajo el capó, pero la sintaxis es bastante similar, por lo que aprender 'Pandas' también te permitirá sentirte cómodo con 'Polars'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diagram_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1. Motivación y presentación\n",
    "\n",
    "Supongamos que tienes un archivo con un millón de líneas de valores separados por comas como este:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diagram_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y necesitas dar respuestas a preguntas básicas como \"¿Qué ciudades tienen un área de más de 450 km² y una población de menos de 10 millones\" con 'NumPy'.\n",
    "\n",
    "La solución de fuerza bruta de introducir toda la tabla en una matriz, 'NumPy' no es una buena opción: normalmente, las matrices 'NumPy' son homogéneas (todos los valores tienen el mismo tipo), por lo que todos los campos se interpretarán como 'cadenas' y las comparaciones no funcionarán como se espera.\n",
    "\n",
    "Sí, 'NumPy' tiene matrices estructuradas y de registros que permiten columnas de distintos tipos, pero están pensadas principalmente para interactuar con código 'C'. Cuando se utilizan para fines generales, tienen las siguientes desventajas:\n",
    "\n",
    "- No es realmente intuitivo (por ejemplo, te enfrentarás a constantes como <f8 y <U8 en todas partes);\n",
    "\n",
    "- Tiene algunos problemas de rendimiento en comparación con las matrices 'NumPy' normales;\n",
    "\n",
    "- Se almacenan de forma contigua en la memoria, por lo que cada adición o eliminación de columna requiere la reasignación de toda la matriz;\n",
    "\n",
    "- Todavía falta mucha funcionalidad de Pandas DataFrames.\n",
    "\n",
    "Tu próximo intento probablemente sería almacenar cada columna como un vector 'NumPy' independiente. Y después de eso, tal vez envolverlas en un vector 'dict' para que sea más fácil restaurar la integridad de la \"base de datos\" si decides agregar o eliminar una fila o dos más adelante. Así es como se vería:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diagram_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo has hecho, ¡felicitaciones! Has dado el primer paso para reimplementar Pandas. \n",
    "\n",
    "Ahora, aquí hay un par de ejemplos de lo que Pandas puede hacer por usted y que 'NumPy' no puede (o requiere un esfuerzo significativo para lograr)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhibición de Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere la siguiente tabla:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diagram_4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe la variada línea de productos de una 'tienda online' con un total de cuatro productos distintos. A diferencia del ejemplo anterior, se puede representar con una matriz 'NumPy' o con un 'DataFrame de Pandas' igualmente bien. Pero veamos algunas operaciones comunes con él."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Clasificación\n",
    "\n",
    "La ordenación por columna es más legible con Pandas, como puedes ver a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diagram_5.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se calcula 'argsort(a[:,1])', la permutación que hace que la segunda columna de 'a' se ordene en orden ascendente y luego la externa 'a[…]' reordena las filas de 'a', según corresponda. Pandas puede hacerlo en un solo paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Ordenar por varias columnas\n",
    "\n",
    "Si necesitamos ordenar por columna de 'price' y desempatar usando la columna de 'weight', la situación empeora para 'NumPy':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diag_6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con 'NumPy', primero ordenamos por 'price' y luego aplicamos un segundo ordenamiento por 'weight'. Un algoritmo de ordenamiento estable garantiza que el resultado del primer ordenamiento no se pierda durante el segundo. Hay otras formas de hacerlo con 'NumPy', pero ninguna es tan simple y elegante como con Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Agregar una columna\n",
    "\n",
    "Agregar columnas es mucho mejor con Pandas, sintácticamente y arquitectónicamente:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Pandas' no necesita reasignar memoria para toda la matriz como 'NumPy'; simplemente agrega una referencia a una nueva columna y actualiza un \"registro\" de los nombres de las columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Búsqueda rápida de elementos\n",
    "\n",
    "Con las matrices 'NumPy', incluso si el elemento que busca es el primero, necesitará un tiempo proporcional al tamaño de la matriz para encontrarlo. Con 'Pandas', puede indexar las columnas que espera que se consulten con más frecuencia y reducir el tiempo de búsqueda a una constante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diag_8.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna de índice tiene las siguientes limitaciones:\n",
    "\n",
    "- Requiere memoria y tiempo para construirse.\n",
    "\n",
    "- Es de sólo lectura (debe reconstruirse después de cada operación de adición o eliminación).\n",
    "\n",
    "- No es necesario que los valores sean únicos, pero la aceleración solo ocurre cuando los elementos son únicos.\n",
    "\n",
    "- Requiere calentamiento: la primera consulta es algo más lenta que en 'NumPy', pero las siguientes son significativamente más rápidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Uniones por columnas\n",
    "\n",
    "Si desea complementar una tabla con información de otra tabla basada en una columna común, 'NumPy' no es de mucha ayuda. 'Pandas' es mejor, especialmente para relaciones '1:n'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diag_9.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En 'Pandas', 'join' tiene todos los modos de unión familiares: 'inner', 'left', 'right' y 'outer'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Agrupación por columnas\n",
    "\n",
    "Otra operación habitual en el análisis de datos es la agrupación por columnas. Por ejemplo, para obtener la cantidad total vendida de cada producto, puede hacer lo siguiente:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_10.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de 'sum', Pandas admite todo tipo de funciones agregadas: 'mean', 'max', 'min', 'count', etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Tablas dinámicas\n",
    "Una de las funciones más potentes de Pandas es una tabla “pivotante”. Es algo así como proyectar un espacio multidimensional en un plano bidimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diag_11.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   client  product  quantity\n",
      "0    John  bananas         5\n",
      "1    John  oranges         3\n",
      "2  Silvia  bananas         4\n",
      "3  Silvia  oranges         2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>product</th>\n",
       "      <th>bananas</th>\n",
       "      <th>oranges</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silvia</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "product  bananas  oranges\n",
       "client                   \n",
       "John           5        3\n",
       "Silvia         4        2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ejemplo de tablas Dinamicas\n",
    "data={'client': ['John','John','Silvia','Silvia'],\n",
    "      'product':['bananas','oranges','bananas','oranges'],\n",
    "      'quantity':[5, 3, 4, 2]\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Aplicando el método 'pivot' para crear una tabla dinámica\n",
    "df.pivot(index='client', columns= 'product', values= 'quantity')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien es posible implementarlo con 'NumPy', esta funcionalidad falta \"de fábrica\", aunque está presente en todas las principales bases de datos relacionales y aplicaciones de hojas de cálculo ( Excel , Google Sheets ).\n",
    "\n",
    "Pandas también tiene una función 'df.pivot_table' que combina agrupación y pivoteo en una sola herramienta.\n",
    "\n",
    "En este punto, es posible que te preguntes por qué alguien usaría 'NumPy' si Pandas es tan bueno. 'NumPy' no es mejor ni peor, solo tiene diferentes casos de uso:\n",
    "\n",
    "- Números aleatorios (por ejemplo, para pruebas)\n",
    "\n",
    "- Álgebra lineal (por ejemplo, para redes neuronales)\n",
    "\n",
    "- Imágenes y pilas de imágenes (por ejemplo, para CNN)\n",
    "\n",
    "- Personal científico de diferenciación, integración, trigonometría y otros.\n",
    "\n",
    "En pocas palabras, las dos diferencias principales entre NumPy y Pandas son las siguientes:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_12.png\">\n",
    "\n",
    "Ahora veamos si esas características se consiguen a costa de una pérdida de rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La velocidad de los pandas\n",
    "\n",
    "He evaluado 'NumPy' y 'Pandas' en una carga de trabajo típica de Pandas: 5 a 100 columnas; 10³ a 10⁸ filas; números enteros y flotantes. Estos son los resultados para 1 fila y 100 millones de filas:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_13.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Parece que en cada operación, 'Pandas' es más lento que 'NumPy'!\n",
    "\n",
    "La situación (como era de esperar) no cambia cuando aumenta el número de columnas. En cuanto al número de filas, la dependencia (en escala logarítmica) se ve así:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_14.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas parece ser 30 veces más lento que NumPy para matrices pequeñas (menos de cien filas) y tres veces más lento para matrices grandes (más de un millón de filas).\n",
    "\n",
    "¿Cómo puede ser? Tal vez sea hora de enviar una solicitud de función para sugerir la reimplementación de Pandas a df.column.values.sum() través de 'df.column.sum()'? La propiedad values aquí proporciona acceso a la matriz 'NumPy' subyacente y da como resultado una aceleración de 3 a 30 veces.\n",
    "\n",
    "La respuesta es no. Pandas es muy lento en esas operaciones básicas porque maneja correctamente los valores faltantes. Pandas necesita NaN (no-un-número) para toda esta maquinaria similar a una base de datos, como la agrupación y el pivoteo, además de que es algo común en el mundo real. En Pandas, se ha trabajado mucho para unificar el uso de 'NaN' en todos los tipos de datos admitidos. Por definición (impuesta a nivel de CPU), nan + cualquier cosa da como resultado nan. Entonces:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_15.png\">\n",
    "\n",
    "pero\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_16.png\">\n",
    "\n",
    "Una comparación justa sería utilizar 'sum' 'np.nan' en lugar de np.sum, 'mean' 'np.nan' en lugar de 'np.mean' y así sucesivamente. Y de repente…\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_17.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Pandas' es 1,5 veces más rápido que 'NumPy' para matrices con más de un millón de elementos. Sigue siendo 15 veces más lento que 'NumPy' para matrices más pequeñas, pero por lo general no importa mucho si la operación se completa en '0,5 ms' o '0,05 ms': de todos modos es rápido.\n",
    "\n",
    "En definitiva, si estás 100 % seguro de que no faltan valores en tus columnas, tiene sentido usar 'df.column.values.sum()' en lugar de 'df.column.sum()' para tener un aumento de rendimiento de 'x3' a 'x30'. En presencia de valores faltantes, la velocidad de Pandas es bastante decente e incluso supera a 'NumPy' para matrices enormes (más de 10⁶ elementos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2. Series e índices\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_18.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Series' es una contraparte de una matriz unidimensional en 'NumPy' y es un componente básico para un 'DataFrame' que representa su columna. Aunque su importancia práctica está disminuyendo en comparación con un 'DataFrame' (puede resolver perfectamente muchos problemas prácticos sin saber qué es una 'serie'), es posible que le resulte difícil comprender cómo funcionan los 'DataFrames' sin aprender primero sobre 'series' e 'índices'.\n",
    "\n",
    "Internamente, 'Series' almacena los valores en un simple vector 'NumPy'. Como tal, hereda sus ventajas (diseño compacto de la memoria, acceso aleatorio rápido) y desventajas (homogeneidad de tipos, eliminaciones e inserciones lentas). Además, Series permite acceder a sus valores por etiqueta utilizando una estructura similar a un diccionario llamada 'index'. Las etiquetas pueden ser de cualquier tipo (comúnmente cadenas y marcas de tiempo). No necesitan ser únicas, pero se requiere la unicidad para aumentar la velocidad de búsqueda y se asume en muchas operaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diag_19.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, ahora cada elemento puede ser direccionado de dos maneras alternativas: por 'etiqueta' (usando el índice) y por 'posición' (sin usar el índice):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diag_20.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A veces, al direccionamiento \"por posición\" se le denomina \"por índice posicional\", lo que no hace más que aumentar la confusión.\n",
    "\n",
    "Obviamente, un par de corchetes no es suficiente para esto. En particular:\n",
    "\n",
    "- s[2:3] No es la forma más conveniente de abordar el elemento 'número 2'\n",
    "\n",
    "- Si las etiquetas son números enteros, 's[1:3]' se vuelve ambiguo. Puede significar etiquetas '1' a '3' inclusive o índices posicionales '1' a '3' excluidos.\n",
    "\n",
    "Para solucionar estos problemas, Pandas tiene dos \"tipos\" más de corchetes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diag_21.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .loc[] siempre utiliza 'etiquetas' e incluye ambos extremos del intervalo;\n",
    "\n",
    "- .iloc[] siempre utiliza 'índices' posicionales y excluye el extremo derecho.\n",
    "\n",
    "El propósito de usar corchetes en lugar de paréntesis aquí es obtener acceso a la conveniente segmentación de 'Python': puede usar dos puntos simples o dobles con el significado familiar de 'start:stop:step'. Como es habitual, falta de inicio ('stop') significa desde el inicio (hasta el 'stop') de la serie. El argumento de 'step' permite hacer referencia a filas pares con s.iloc[::2]y obtener elementos en orden inverso cons['Paris':'Oslo':-1]\n",
    "\n",
    "También admiten la indexación booleana (indexación con una matriz de booleanos), como muestra esta imagen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diag_22.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y puedes ver cómo admiten la 'indexación elegante' (indexación con una matriz de números enteros) en esta imagen:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_23.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo peor de 'Series' es su representación visual: por alguna razón, no recibió una agradable apariencia de texto enriquecido, por lo que parece un ciudadano de 'segunda clase' en comparación con un 'DataFrame':\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_24.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He 'parcheado' la serie para que se vea mejor, como se muestra a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_25.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped=\"\">\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "<thead style=\"border-bottom: none;\">\n",
       "<tr style=\"text-align: right;\">\n",
       "<th></th>\n",
       "<th>animal</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<th style=\"border-right: 1px solid #666;\">a</th>\n",
       "<td>cat</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<th style=\"border-right: 1px solid #666;\">b</th>\n",
       "<td>dog</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<th style=\"border-right: 1px solid #666;\">c</th>\n",
       "<td>panda</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<th style=\"border-right: 1px solid #666;\">d</th>\n",
       "<td>cat</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<th style=\"border-right: 1px solid #666;\">e</th>\n",
       "<td>dragon</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "a       cat\n",
       "b       dog\n",
       "c     panda\n",
       "d       cat\n",
       "e    dragon\n",
       "Name: animal, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdi\n",
    "\n",
    "pdi.patch_series_repr(footer=False)\n",
    "\n",
    "pd.Series(['cat', 'dog', 'panda', 'cat', 'dragon'], index= list('abcde'), name='animal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La 'línea vertical' significa que se trata de una serie, no de un 'marco de datos'. El pie de página está deshabilitado aquí, pero puede ser útil para mostrar tipos de datos, especialmente con elementos categóricos.\n",
    "\n",
    "También puedes mostrar varias 'Series' o 'DataFrames' uno al lado del otro con 'pdi'.sidebyside(obj1, obj2, …):\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_26.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdi(significa 'p' y como se 'ilustra' ) es una biblioteca de código abierto en 'github'' con esta y otras funciones para este artículo. Para usarla, escribe\n",
    "\n",
    "'pip install pandas-illustrated'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Índice\n",
    "\n",
    "El objeto responsable de obtener los elementos de la serie (así como las filas y columnas del DataFrame) por etiqueta se denomina 'índice'. Es rápido: puede obtener el resultado en tiempo constante, ya sea que tenga cinco elementos o 5 mil millones de elementos.\n",
    "\n",
    "'Indexes' una criatura verdaderamente polimórfica. De manera predeterminada, cuando crea una serie (o un DataFrame) sin argumentos 'index', se inicializa en un objeto perezoso similar al 'range()' de Python . Al igual que 'range()', apenas utiliza memoria y proporciona las etiquetas que coinciden con la indexación posicional. Creemos una serie de un millón de elementos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1000000, step=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s= pd.Series(np.zeros(10**6))\n",
    "s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memoria usada en 'bytes': 132\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "indice = pd.RangeIndex(start=0, stop= 1000000, step= 1)\n",
    "print(f\"Memoria usada en 'bytes': {indice.memory_usage()}\") # Número de bytes\n",
    "                                                            # Lo mismo que para Series([0.]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, si eliminamos un elemento, el índice se transforma implícitamente en una estructura similar a un diccionario, de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([     0,      2,      3,      4,      5,      6,      7,      8,      9,\n",
       "           10,\n",
       "       ...\n",
       "       999990, 999991, 999992, 999993, 999994, 999995, 999996, 999997, 999998,\n",
       "       999999],\n",
       "      dtype='int64', length=999999)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s1= indice.drop(1) \n",
    "s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Esta estructura consume 8 MB de memoria! Para deshacerse de ella y volver a la estructura liviana de tipo rango, escriba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              0\n",
      "1              2\n",
      "2              3\n",
      "3              4\n",
      "4              5\n",
      "           ...  \n",
      "999994    999995\n",
      "999995    999996\n",
      "999996    999997\n",
      "999997    999998\n",
      "999998    999999\n",
      "Length: 999999, dtype: int64\n",
      "\n",
      "RangeIndex(start=0, stop=999999, step=1)\n",
      "\n",
      "Memoria usada en 'bytes': 132\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s2= pd.Series(s1).reset_index(drop=True)\n",
    "print(s2)\n",
    "print()\n",
    "s2 = pd.RangeIndex(start=0, stop= 999999, step= 1)\n",
    "print(indice)\n",
    "print()\n",
    "print(f\"Memoria usada en 'bytes': {s2.memory_usage()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no conoce Pandas, es posible que se pregunte por qué Pandas no lo hizo por sí solo. Bueno, para las etiquetas no numéricas, es bastante obvio: ¿por qué (y cómo) Pandas, después de eliminar una fila, volvería a etiquetar todas las filas subsiguientes? Para las etiquetas numéricas, la respuesta es un poco más complicada.\n",
    "\n",
    "Primero, como ya hemos visto, Pandas te permite referenciar filas puramente por posición, por lo que si quieres direccionar la fila número 5 después de eliminar la fila número 3, puedes hacerlo sin reindexar (para eso está iloc).\n",
    "\n",
    "En segundo lugar, mantener las etiquetas originales es una forma de mantener una conexión con un momento del pasado, como un botón para \"guardar el juego\". Imagina que tienes una tabla grande con cien columnas y un millón de filas y necesitas encontrar algunos datos. Estás haciendo varias consultas una por una, cada vez acotando la búsqueda, pero mirando solo un subconjunto de las columnas, porque no es práctico ver todos los cien campos al mismo tiempo. Ahora que has encontrado las filas de interés, quieres ver toda la información sobre ellas en la tabla original. Un índice numérico te ayuda a obtenerla inmediatamente sin ningún esfuerzo adicional. Esquemáticamente, se ve así:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_27.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, es una buena idea mantener los valores de índice únicos. Por ejemplo, no obtendrá un aumento en la velocidad de búsqueda en presencia de valores duplicados en el índice. Pandas no tiene una \"restricción única\" como las bases de datos relacionales ( la característica aún es experimental), pero tiene funciones para verificar si los valores en el índice son únicos y para deshacerse de los duplicados de varias maneras.\n",
    "\n",
    "A veces, una sola columna no es suficiente para identificar de forma única la fila. Por ejemplo, a veces sucede que las ciudades con el mismo nombre se encuentran en diferentes países o incluso en diferentes regiones del mismo país. Por lo tanto, (city, state) es un mejor candidato para identificar un lugar que una sola 'city'. En las bases de datos, se denomina \"clave principal compuesta\". En Pandas, se denomina 'MultiIndex' (consulte la Parte 4 a continuación) y cada columna dentro del índice se denomina \"nivel\".\n",
    "\n",
    "Otra cualidad sustancial de un índice es que es inmutable. A diferencia de las columnas ordinarias en el 'DataFrame', no se puede modificar en el lugar. Cualquier cambio en el índice implica obtener datos del índice anterior, modificarlos y volver a adjuntar los nuevos datos como un nuevo índice. Por ejemplo, para convertir nombres de columnas en cadenas en el lugar (ahorra memoria), escribir 'df.columns = df.columns.astype(str)' o no en el lugar (útil para encadenar métodos). La mayoría de las veces, esto sucede de forma transparente (por ejemplo, al agregar o eliminar una columna), pero es la inmutabilidad la que no le permite simplemente escribir, por lo que debe recurrir a un método menos obvio '.df.set_axis(df.columns.astype(str), axis=1)' \"df.City.name = 'city'\" \"df.rename(columns={'City': 'city'})\"\n",
    "\n",
    "El índice tiene un nombre (en el caso de MultiIndex, cada nivel tiene un nombre). Lamentablemente, este nombre no se usa lo suficiente en Pandas. Una vez que haya incluido la columna en el índice, 'df.column_name' ya no podrá utilizar la notación conveniente y deberá volver a la menos legible df.indexo a la más universal 'df.loc[]'. La situación empeora con 'MultiIndex'. Una excepción destacada es 'df.merge' que puede especificar la columna que se fusionará por nombre, sin importar si esta columna pertenece al índice o no.\n",
    "\n",
    "Las columnas se etiquetan utilizando exactamente el mismo índice que las filas, aunque esto puede no ser evidente a partir de los argumentos del 'pd.DataFrameconstructor'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encontrar elemento por valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere el siguiente objeto 'Serie':\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_28.png\">\n",
    "\n",
    "'Index' ofrece una forma rápida y cómoda de buscar un valor por etiqueta. Pero ¿qué ocurre con la búsqueda de una etiqueta por valor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diag_29.png\">\n",
    "\n",
    "He escrito un par de instrucciones llamados find() y findall() que son rápidos (ya que eligen automáticamente el comando real en función del tamaño de la serie) y más fáciles de usar. Así es como se ve el código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import pdi\n",
    ">>> pdi.find(s, 2)\n",
    "\n",
    "'penguin'\n",
    "\n",
    ">>> pdi.findall(s, 4)\n",
    "\n",
    "Index(['cat', 'dog'], dtype= \"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores faltantes\n",
    "\n",
    "Los desarrolladores de Pandas han tenido especial cuidado con los valores faltantes. Normalmente, se recibe un dataframe con 'NaN' proporcionando una bandera a 'read_csv'. De lo contrario, se puede utilizar 'None' en el constructor o en un operador de asignación (funcionará a pesar de que se implementa de forma ligeramente diferente para diferentes tipos de datos), por ejemplo:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_31.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que puedes hacer con los 'NaN' es saber si tienes alguno. Como se ve en la imagen de arriba, 'isna()' genera una matriz booleana y proporciona la cantidad total de valores faltantes..'sum()'\n",
    "\n",
    "Ahora que sabes que están ahí, puedes optar por deshacerte de ellos eliminándolos, rellenándolos con un valor constante o interpolándolos, como se muestra a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_32.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, puedes seguir usándolos. La mayoría de las funciones de Pandas ignoran sin problemas los valores faltantes:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_33.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones más avanzadas ( median, rank, quantile, etc.) también lo hacen.\n",
    "\n",
    "Las operaciones aritméticas se alinean con 'index':\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_34.png\">\n",
    "\n",
    "Los resultados son inconsistentes en presencia de valores no únicos en el índice. No utilice operaciones aritméticas en series con un índice no único."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparaciones\n",
    "\n",
    "Comparar matrices con valores faltantes es complicado.\n",
    "\n",
    "Para empezar,\n",
    "- Nonesiempre es igual a None,\n",
    "\n",
    "- NaN( np.nantambién conocido como math.nanaka float('nan')) nunca es igual a NaN, y si todavía no es lo suficientemente extraño para ti...\n",
    "\n",
    "- Al comparar pd.NAcon cualquier cosa siempre devuelve pd.NA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> None == None\n",
    "\n",
    "True\n",
    "\n",
    ">>> np.nan == np.nan\n",
    "\n",
    "False\n",
    "\n",
    ">>> np.NA == np.NA\n",
    "\n",
    "<NA>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se trata de matrices, la cosa empeora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> np.all(pd.Series([1, None, 3.]) == pd.Series([1., None, 3.])) # Esto es 'np.nan'\n",
    "\n",
    "False\n",
    "\n",
    ">>> np.all(pd.Series(['a', None, 'c']) == pd.Series(['a', None, 'c'])) # Esto es 'None'\n",
    "\n",
    "False\n",
    "\n",
    "np.all(pd.Series([1, None, 3], dtype='Int64') == pd.Series([1, None, 3], dtype='Int64')) # Esto es pd.NA\n",
    "\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un método sencillo para compararlos correctamente es reemplazar todos estos tipos de pd.NA(que significa 'no disponible') con algo que seguramente no estará en la matriz. Por ejemplo, con '', -1 o ∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> np.all(s1.fillna(np.inf) == s2.fillna(np.inf)) # Funciona para todos los tipos de datos\n",
    "\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una mejor manera es utilizar una función de comparación estándar de 'NumPy' o 'Pandas':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> s = pd.Series([1., None, 3.]) \n",
    ">>> np.allclose(s.values, s.values, equal_nan=True) \n",
    "\n",
    "True \n",
    "\n",
    ">>> len(s.compare(s)) == 0 \n",
    "\n",
    "True \n",
    "\n",
    ">>> pd.testing.assert_series_equal(s, s) # devuelve None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí, 'compare' devuelve una lista de diferencias (un DataFrame, en realidad), 'allclose' devuelve 'array_equal' un valor booleano directamente y 'assert_series_equal' genera una excepción detallada cuando se encuentran diferencias.\n",
    "\n",
    "Al comparar 'DataFrames' con tipos que no son \"nativos\" de 'NumPy' (por ejemplo 'object', 'Int64', , tipos mixtos, etc.), la comparación de 'NumPy' falla ( problema n.° 19205 ), mientras que 'Pandas' funciona perfectamente bien. Así es como se ve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> df = pd.DataFrame({'a': [1., Ninguno, 3.], 'b': ['x', Ninguno, 'z']}) \n",
    ">>> np.allclose(df.values, df.values, equal_nan=True) \n",
    "\n",
    "TypeError \n",
    "\n",
    "<...> \n",
    ">>> len(df.compare(df)) == 0 \n",
    "\n",
    "True \n",
    "\n",
    ">>> pd.testing.assert_frame_equal(df, df) # devuelve Ninguno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una ventaja agradable de usar funciones es su capacidad de comparar números flotantes correctamente (con tolerancias absolutas y relativas personalizables), tal como , de modo que dentro de las matrices 0,1+0,2 parece ser igual a 0,3: 'assert_anything_equal' 'np.allclose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> 0.1+0.2 == 0.3\n",
    " \n",
    "Falso \n",
    "\n",
    ">>> assert_series_equal(pd.Series([0.1+0.2]), pd.Series([0.3])) # sin excepción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que todos los métodos descritos anteriormente requieren que la forma (NumPy) o tanto la forma como el índice (Pandas) sean idénticos. De lo contrario,\n",
    "los operadores de comparación 'compare' llegan hasta el punto de generar un 'ValueError' mientras 'np.array_equal' retorna 'False' y genera un con 'deltas' como de costumbre. La única excepción es que transmite las matrices antes de la comparación: 'assert_anything_equal' 'AssertionError' 'np.allclose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> np.array_equal(np.array([1, 1, 1]), np.array[1]) \n",
    "\n",
    "Falso \n",
    "\n",
    ">>> np.allclose(np.array([1, 1, 1]), np.array[1])\n",
    " \n",
    "Verdadero \n",
    "\n",
    ">>> np.testing.assert_array_equal(np.array([1, 1, 1]), np.array[1]) \n",
    "\n",
    "Error de afirmación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anexiones, inserciones, eliminaciones\n",
    "\n",
    "Aunque se supone que los objetos Series son inmutables en tamaño, es posible agregar, insertar y eliminar elementos en el lugar, pero todas esas operaciones son:\n",
    "\n",
    "- Lento, ya que requieren reasignar memoria para todo el objeto y actualizar el índice;\n",
    "\n",
    "- dolorosamente inconveniente\n",
    "\n",
    "Aquí hay una forma de insertar un valor y dos formas de eliminar los valores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diag_35.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El segundo método para eliminar valores (a través de drop) es más lento y puede generar errores complejos en presencia de valores no únicos en el índice.\n",
    "\n",
    "Pandas tiene el método, pero solo puede insertar columnas (no filas) en un marco de datos (y no funciona en absoluto con series).df.insert\n",
    "\n",
    "Otro método para agregar e insertar es cortar el DataFrame con iloc, aplicar las conversiones necesarias y luego volver a colocarlo con concat. He implementado una función llamada insertque automatiza el proceso:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diagram_36.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que (al igual que en df.insert) el lugar a insertar, viene dado por una posición 0<=i<=len(s), no por la etiqueta del elemento del índice.\n",
    "\n",
    "Puede proporcionar una etiqueta para un nuevo elemento. Para un índice no numérico, es obligatorio. Por ejemplo:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_37.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para especificar el punto de inserción por etiqueta, puede combinar 'pdi.find' con 'pdi.insert', como se muestra a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_38.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que, a diferencia de 'df.insert', 'pdi.insert' devuelve una copia en lugar de modificar la 'Serie/DataFrame' en el lugar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estadistica\n",
    "\n",
    "Pandas ofrece un espectro completo de funciones estadísticas que pueden brindarle una idea de lo que hay en una serie o un marco de datos de un millón de elementos sin tener que desplazarse manualmente por los datos.\n",
    "\n",
    "Todas las funciones estadísticas de Pandas ignoran los 'NaN', como puedes ver a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_39.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que 'Pandas std' ofrece resultados diferentes a los de 'NumPy.std'.\n",
    "\n",
    "Dado que se puede acceder a cada elemento de una serie mediante una etiqueta o un índice posicional, existe una función hermana para argmin (argmax) llamada idxmin ( idxmax), que se muestra en la imagen:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_40.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra una lista de funciones estadísticas autodescriptivas de Pandas como referencia:\n",
    "\n",
    "- std, desviación estándar de la muestra;\n",
    "\n",
    "- var, varianza imparcial;\n",
    "\n",
    "- sem, error estándar no sesgado de la media;\n",
    "\n",
    "- quantile, cuantil de muestra ( s.quantile(0.5) ≈ s.median());\n",
    "\n",
    "- mode, el(los) valor(es) que aparecen con más frecuencia;\n",
    "\n",
    "- nlargest y nsmallest, por defecto, en orden de aparición;\n",
    "\n",
    "- diff, primera diferencia discreta;\n",
    "\n",
    "- cumsum y cumprod, suma acumulada, y producto;\n",
    "\n",
    "- cummin y cummax, mínimo y máximo acumulativo.\n",
    "\n",
    "Y algunas funciones estadísticas más especializadas:\n",
    "\n",
    "- pct_change, cambio porcentual entre el elemento actual y el anterior;\n",
    "\n",
    "- skew, asimetría imparcial (tercer momento);\n",
    "\n",
    "- kurt o bien kurtosis, curtosis imparcial (cuarto momento);\n",
    "\n",
    "- cov, corr y autocorr, covarianza, correlación y autocorrelación;\n",
    "\n",
    "- rolling, weighted, y ventanas exponentially weighted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datos duplicados\n",
    "\n",
    "Se tiene especial cuidado en detectar y tratar los datos duplicados, como se puede ver en la imagen:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_41.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'drop_duplicates' y 'duplicated' puede mantener la última ocurrencia en lugar de la primera.\n",
    "\n",
    "De hecho, estas dos funciones son complementarias entre sí:\n",
    "df.drop_duplicates() == df[~df.duplicated()]\n",
    "\n",
    "Tenga en cuenta que 's.unique()' es más rápido que 'np.unique' (O(N) vs O(NlogN)) y conserva el orden en lugar de devolver los resultados ordenados como np.unique lo hace.\n",
    "\n",
    "Los valores faltantes se tratan como valores ordinarios, lo que a veces puede generar resultados sorprendentes.\n",
    "\n",
    "<img src=\"img/Articulo_2_diag_42.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si desea excluir los 'NaN', debe hacerlo explícitamente. En este ejemplo en particular, 's.dropna().is_unique == True'.\n",
    "\n",
    "También existe una familia de propiedades monótonas con nombres autodescriptivos:\n",
    "\n",
    "- s.is_monotonic_increasing,\n",
    "\n",
    "- s.is_monotonic_decreasing, y, de manera bastante inesperada,\n",
    "\n",
    "- s.is_monotonic — que es un sinónimo 's.is_monotonic_increasing()' y devuelve 'False' una \n",
    "serie decreciente monótona (afortunadamente, obsoleto y eliminado en Pandas 2.0)\n",
    "\n",
    "No hay funciones documentadas que verifiquen la monotonía estricta, pero puedes construir una fácilmente combinándolas con 's.unique', por ejemplo, para verificar si saumenta estrictamente de manera monótona, escribe\n",
    "'s.unique' y 's.is_monotonic_increasing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cadenas y expresiones regulares\n",
    "\n",
    "Prácticamente todos los métodos de cadena de Python tienen una versión vectorizada en Pandas:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_43.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando una operación de este tipo devuelve varios valores, tienes varias opciones sobre cómo utilizarlos:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_44.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si conoce expresiones regulares, Pandas también tiene versiones vectorizadas de las operaciones comunes con ellas:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_45.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group by\n",
    "\n",
    "Una operación común en el procesamiento de datos es calcular algunas estadísticas no sobre todo el conjunto de datos sino sobre ciertos grupos de ellos. El primer paso es construir un objeto perezoso proporcionando criterios para dividir una serie (o un marco de datos) en grupos. Este objeto perezoso no tiene una representación significativa, pero puede ser:\n",
    "\n",
    "- iterado (produce la clave de agrupación y la subserie correspondiente, ideal para depuración):\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_46.png\">\n",
    "\n",
    "- Se consulta de la misma manera que las series ordinarias para obtener una determinada propiedad de cada grupo (es más rápido que la iteración):\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_47.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, dividimos la serie en tres grupos según la parte entera de dividir los valores por 10. Para cada grupo, solicitamos la suma de los elementos, la cantidad de elementos y el valor promedio en cada grupo.\n",
    "\n",
    "Además de esas funciones de agregación, puedes acceder a elementos específicos en función de su posición o valor relativo dentro de un grupo. Así es como se ve:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_48.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puede calcular varias funciones en una sola llamada con g.agg(['min', 'max'])o mostrar un montón de funciones estadísticas a la vez con 'g.describe()'.\n",
    "\n",
    "Si esto no es suficiente, también puedes pasar los datos a través de tu propia función de Python. Puede ser:\n",
    "\n",
    "- Una función 'f' que acepta un grupo x(un objeto Serie) y genera un único valor (por ejemplo, sum()) cong.apply(f)\n",
    "\n",
    "- Una función 'f' que acepta un grupo x(un objeto Serie) y genera un objeto Serie del mismo tamaño que x(por ejemplo, cumsum()) cong.transform(f)\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_49.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los ejemplos anteriores, los datos de entrada están ordenados. Esto no es necesario para 'groupby'. En realidad, funciona igual de bien si los elementos del grupo no se almacenan de forma consecutiva, por lo que es más cercano a 'collections.defaultdict' que a 'itertools.groupby'. Y siempre devuelve un índice sin duplicados.\n",
    "\n",
    "<Img src=\"Img/Articulo_2_diag_50.png\">\n",
    "\n",
    "A diferencia de 'defaultdict' la cláusula 'GROUP BY' de una base de datos relacional, Pandas 'groupby' ordena los resultados por nombre de grupo. Puede desactivarse con 'sort='False', como verá en el código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> s = pd.Series([1, 3, 20, 2, 10])\n",
    ">>> for k, v in s.groupby(s//10, sort=False):\n",
    "       print(k, v.tolist())\n",
    "0 [1, 3, 2]\n",
    "2 [20]\n",
    "1 [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargo de responsabilidad: En realidad, 'g.apply(f)' es más versátil de lo descrito anteriormente:\n",
    "\n",
    "- Si f(x) devuelve una serie del mismo tamaño que x, puede imitar la transformación\n",
    "\n",
    "- Si f(x) devuelve una serie de diferente tamaño o un marco de datos, da como resultado una serie con un Multiindex correspondiente.\n",
    "\n",
    "Pero los documentos advierten que esos usos pueden ser más lentos que los métodos correspondientes transform, aggasí que tenga cuidado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3. DataFrame\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_51.png\">\n",
    "\n",
    "La estructura de datos principal de Pandas es un 'DataFrame'. Agrupa una matriz bidimensional con etiquetas para sus filas y columnas. Consta de una serie de objetos Series (con un índice compartido), cada uno de los cuales representa una sola columna y posiblemente tenga diferentes tipos de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lectura y escritura de archivos CSV\n",
    "\n",
    "Una forma común de construir un 'DataFrame' es leyendo un archivo CSV (valores separados por comas), como muestra esta imagen:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_52.png\">\n",
    "\n",
    "La función es una herramienta totalmente automatizada y muy personalizable. Si quieres aprender una sola cosa sobre Pandas, aprende a usarlo. ¡ Valdrá la pena!:) 'pd.read_csv()read_csv'\n",
    "\n",
    "A continuación se muestra un ejemplo de análisis de un archivo CSV no estándar:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_53.png\">\n",
    "\n",
    "Y una breve descripción de algunos de los argumentos:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_54.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que CSV no tiene una especificación estricta, a veces es necesario un poco de ensayo y error para leerlo correctamente. Lo bueno 'read_csv' es que detecta automáticamente muchas cosas, entre ellas:\n",
    "\n",
    "- Nombres y tipos de columnas,\n",
    "\n",
    "- Representación de booleanos,\n",
    "\n",
    "- Representación de valores faltantes, etc.\n",
    "\n",
    "Al igual que con cualquier automatización, es mejor asegurarse de que haya hecho lo correcto. Si los resultados de escribir simplemente 'df' en una celda de Jupyter resultan ser demasiado largos (o demasiado incompletos), puede probar lo siguiente:\n",
    "\n",
    "- df.head(5) o df[:5] muestra las primeras cinco filas\n",
    "\n",
    "- df.dtypes devuelve los tipos de columna\n",
    "\n",
    "- df.shape devuelve el número de filas y columnas\n",
    "\n",
    "- df.info() Resume toda la información relevante\n",
    "\n",
    "Es una buena idea establecer una o varias columnas como índice. La siguiente imagen muestra este proceso:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_55.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index tiene muchos usos en Pandas:\n",
    "\n",
    "- Hace que las búsquedas por columnas indexadas sean más rápidas;\n",
    "\n",
    "- Las operaciones aritméticas, el apilamiento y la unión se alinean por índice, etc.\n",
    "\n",
    "Todo esto se produce a costa de un consumo de memoria algo mayor y una sintaxis un poco menos obvia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construyendo un DataFrame\n",
    "\n",
    "Otra opción es construir un marco de datos a partir de datos ya almacenados en la memoria. Su constructor es tan extraordinariamente omnívoro que puede convertir (o encapsular) cualquier tipo de datos que le introduzcas:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_56.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el primer caso, en ausencia de etiquetas de fila, Pandas etiquetó las filas con números enteros consecutivos. En el segundo caso, hizo lo mismo con las filas y las columnas. Siempre es una buena idea proporcionar a Pandas los nombres de las columnas en lugar de las etiquetas de números enteros (usando el columnsargumento) y, a veces, los nombres de las filas (usando el indexargumento, aunque rowspuede sonar más intuitivo). Esta imagen te ayudará:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_57.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para asignar un nombre a la columna de índice, escriba df.index.name = 'city_name' o usepd.DataFrame(..., index=pd.Index(['Oslo', 'Vienna', 'Tokyo'], name='city_name')).\n",
    "\n",
    "La siguiente opción es construir un DataFrame a partir de un diccionario de vectores 'NumPy' o una matriz NumPy 2D:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_58.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe cómo los population valores se convirtieron en flotantes en el segundo caso. En realidad, esto ocurrió antes, durante la construcción de la matriz 'NumPy'. Otra cosa que debe tener en cuenta aquí es que la construcción de un marco de datos a partir de una matriz 'NumPy' 2D es una vista predeterminada. Eso significa que al cambiar los valores en la matriz original se cambia el marco de datos y viceversa. Además, ahorra memoria.\n",
    "\n",
    "Este modo también se puede habilitar en el primer caso (un diccionario de vectores NumPy) configurando copy=False. Sin embargo, es muy frágil. Operaciones simples pueden convertirlo en una copia sin previo aviso.\n",
    "\n",
    "Dos opciones más (menos útiles) para crear un DataFrame son:\n",
    "\n",
    "- De una lista de diccionarios (donde cada diccionario representa una sola fila, sus claves son nombres de columnas y sus valores son los valores de celda correspondientes)\n",
    "\n",
    "- De un 'dict' de Series (donde cada Serie representa una columna; devuelve una copia por defecto, se le puede indicar que devuelva una vista con copy=False).\n",
    "\n",
    "Si registra datos de transmisión \"sobre la marcha\", su mejor opción es utilizar un diccionario de listas o una lista de listas porque Python preasigna espacio de manera transparente al final de una lista para que las adiciones sean rápidas. Ni las matrices de 'NumPy' ni los DataFrame de Pandas lo hacen. Otra posibilidad (si conoce la cantidad de filas de antemano) es preasigna memoria manualmente con algo como DataFrame(np.zeros)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operaciones básicas con DataFrames\n",
    "\n",
    "Lo mejor de DataFrame (en mi opinión) es que puedes:\n",
    "\n",
    "- Acceder fácilmente a sus columnas, por ejemplo, df.areadevuelve valores de columna (o alternativamente, df[‘area’] — bueno para nombres de columnas que contienen espacios)\n",
    "\n",
    "- Operar las columnas como si fueran variables independientes, por ejemplo, después de df.population /= 10**6 almacenar la población en millones, y el siguiente comando crea una nueva columna llamada 'densidad' calculada a partir de los valores de las columnas existentes:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_59.png\">\n",
    "\n",
    "Tenga en cuenta que al crear una nueva columna, los corchetes son obligatorios incluso si su nombre no contiene espacios.\n",
    "\n",
    "Además, puedes utilizar operaciones aritméticas en columnas incluso de diferentes DataFrames, siempre que sus filas tengan etiquetas significativas, como se muestra a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_60.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'DataFrame' a partir de un 'Diccionario' de 'Lista'\n",
      "     name  population    area\n",
      "0    Oslo      698660   480.8\n",
      "1  Vienna     1911191   414.8\n",
      "2   Tokyo    14043239  2194.1\n",
      "\n",
      "'DataFrame' a partir de una 'Lista' de 'Lista'\n",
      "        0         1       2\n",
      "0    Oslo    698660   480.8\n",
      "1  Vienna   1911191   414.8\n",
      "2   Tokyo  14043239  2194.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Construyendo un DataFrame\n",
    "\n",
    "# De un dicionario de lista\n",
    "df= pd.DataFrame({'name':['Oslo','Vienna','Tokyo'],\n",
    "              'population':[698660,1911191,14043239],\n",
    "              'area':[480.8, 414.8, 2194.1]\n",
    "    \n",
    "})\n",
    "\n",
    "# De una lista de lista\n",
    "df1= pd.DataFrame([['Oslo', 698660, 480.8],\n",
    "                   ['Vienna', 1911191, 414.8],\n",
    "                   ['Tokyo', 14043239, 2194.1]  \n",
    "])\n",
    "\n",
    "print(\"'DataFrame' a partir de un 'Diccionario' de 'Lista'\")\n",
    "print(df)\n",
    "print()\n",
    "print(\"'DataFrame' a partir de una 'Lista' de 'Lista'\")\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexación de DataFrames\n",
    "\n",
    "Como ya hemos visto en la sección Series, los corchetes comunes simplemente no son suficientes para satisfacer todas las necesidades de indexación. No se puede acceder a las filas por etiquetas, no se puede acceder a las filas disjuntas por índice posicional y ni siquiera se puede hacer referencia a una sola celda, ya que df['x', 'y'] está reservada para MultiIndex.\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_61.png\">\n",
    "\n",
    "Para satisfacer esas necesidades, los DataFrames, al igual que las series, tienen dos modos de indexación alternativos: 'loc' para indexar por etiquetas y 'iloc' para indexar por índice posicional.\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_62.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Pandas, hacer referencia a varias filas o columnas es una copia, no una vista. Pero es un tipo especial de copia que permite realizar asignaciones en su totalidad:\n",
    "\n",
    "- df.loc['a']=10 Trabajos (una sola fila se puede escribir como un todo)\n",
    "\n",
    "- df.loc['a']['A']=10 Trabajos (el acceso al elemento se propaga al original df)\n",
    "\n",
    "- df.loc['a':'b'] = 10 Trabajos (asignar a un subarreglo como un trabajo completa)\n",
    "\n",
    "- df.loc['a':'b']['A'] = 10 no (asignar a sus elementos no lo hace).\n",
    "\n",
    "En el último caso, el valor solo se establecerá en una copia de una porción y no se reflejará en el original df(se mostrará una advertencia en consecuencia).\n",
    "\n",
    "Dependiendo de la situación existen diferentes soluciones:\n",
    "\n",
    "1. Quiere cambiar el marco de datos original df. Entonces use\n",
    "df.loc['a':'b', 'A'] = 10\n",
    "\n",
    "2. Ha realizado la copia intencionalmente y desea trabajar en esa copia:\n",
    "df1 = df.loc['a':'b']; df1['A']=10 # SettingWithCopy warning para deshacerse de una advertencia en esta situación, conviértala en una copia real:\n",
    "\n",
    "df1 = df.loc['a':'b'].copy(); df1['A']=10\n",
    "\n",
    "Pandas también admite una sintaxis 'NumPy' conveniente para la indexación booleana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Img/Articulo_2_diag_63.png\">\n",
    "\n",
    "Al utilizar varias condiciones, estas deben estar entre paréntesis, como puedes ver a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_64.png\">\n",
    "\n",
    "Cuando esperas que se devuelva un único valor, necesitas tener especial cuidado.\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_65.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que potencialmente podría haber varias filas que coincidan con la condición, 'loc' se devolvió una serie. Para obtener un valor escalar, puede utilizar:\n",
    "\n",
    "- float(s) o una más universal s.item()que generará ValueError a menos que haya exactamente un valor en la serie\n",
    "\n",
    "- s.iloc[0] que solo lanzará una excepción cuando no se encuentre nada; además, es el único que admite asignaciones: df[…].iloc[0] = 100, pero seguramente no lo necesitas cuando quieres modificar todas las coincidencias: df[…] = 100.\n",
    "\n",
    "Alternativamente, puede utilizar consultas basadas en cadenas:\n",
    "\n",
    "- df.query('name==\"Vienna\"')\n",
    "\n",
    "- df.query('population>1e6 and area<1000')\n",
    "\n",
    "Son más cortos, funcionan muy bien con 'MultiIndex' y los operadores lógicos tienen prioridad sobre los operadores de comparación (se requieren menos paréntesis), pero solo pueden filtrar por filas y no se puede modificar el 'DataFrame' a través de ellos.\n",
    "\n",
    "Varias bibliotecas de terceros le permiten usar la sintaxis SQL para consultar los DataFrames directamente (duckdb) o indirectamente copiando el dataframe a 'SQLite' y envolviendo los resultados nuevamente en objetos Pandas (pandasql). Como era de esperar, el método directo es más rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name  population    area\n",
      "0    Oslo      698660   480.8\n",
      "1  Vienna     1911191   414.8\n",
      "2   Tokyo    14043239  2194.1\n",
      "\n",
      "Nombres de paises con poblaciones mayores de un millon de habitantes\n",
      "     name\n",
      "1  Vienna\n",
      "2   Tokyo\n",
      "\n",
      "Paises con poblaciones mayores de un millon de habitantes\n",
      "y área menor de 1000\n",
      "     name  population   area\n",
      "1  Vienna     1911191  414.8\n",
      "\n",
      "Area de 'Viena'\n",
      "    area\n",
      "1  414.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de Indexacion de diccionario\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print('Nombres de paises con poblaciones mayores de un millon de habitantes')\n",
    "print(df.loc[df.population>10**6, ['name']])\n",
    "print()\n",
    "print('Paises con poblaciones mayores de un millon de habitantes')\n",
    "print('y área menor de 1000')\n",
    "print(df.loc[(df.population>10**6) & (df.area<1000), ['name', 'population', 'area']])\n",
    "print()\n",
    "print(\"Area de 'Viena'\")\n",
    "print(df.loc[df.name=='Vienna', ['area']])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aritmética de DataFrame\n",
    "\n",
    "Puede aplicar operaciones ordinarias como sumar, restar, multiplicar, dividir, módulo, potencia, etc., a marcos de datos, series y combinaciones de los mismos.\n",
    "\n",
    "Todas las operaciones aritméticas se alinean con las etiquetas de filas y columnas:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_66.png\">\n",
    "\n",
    "En operaciones mixtas entre 'DataFrames' y 'Series', la Serie (Dios sabe por qué) se comporta (y transmite) como un vector de fila y se alinea en consecuencia:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_67.png\">\n",
    "\n",
    "Probablemente para mantenernos en línea con las listas y los vectores 'NumPy' 1D (que no están alineados por etiquetas y se espera que tengan el mismo tamaño que si el 'DataFrame' fuera una simple matriz 'NumPy' 2D):\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_68.png\">\n",
    "\n",
    "Entonces, en el desafortunado (y, por coincidencia, ¡el más habitual!) caso de dividir un marco de datos por una serie de vectores de columna, debes usar métodos en lugar de operadores, como puedes ver a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_69.png\">\n",
    "\n",
    "Debido a esta decisión cuestionable, siempre que necesites realizar una operación mixta entre un DatFrame y una serie tipo columna, debes buscarla en la documentación (o memorizarla):\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_70.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combinación de DataFrames\n",
    "\n",
    "Pandas tiene una gran cantidad de funciones:\n",
    "\n",
    "— concat(concatenación),\n",
    "\n",
    "— join, merge y merge_asof(fusiones de estilo base de datos),\n",
    "\n",
    "— combine_first, combiney update(superposición de un 'df' sobre el otro)\n",
    "que básicamente hacen lo mismo: combinan información de varios dataframes en uno. Pero cada una de ellas lo hace de manera ligeramente diferente, ya que están diseñadas para diferentes casos de uso:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_71.png\">\n",
    "\n",
    "Ahora veremos algunos detalles intrincados sobre las diferentes opciones, modos y cómo funcionan con 'MultiIndex'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apilamiento vertical\n",
    "\n",
    "Esta es probablemente la forma más sencilla de combinar dos o más marcos de datos en uno: se toman las filas del primero y se añaden las filas del segundo al final. Para que funcione, esos dos 'DataFrame' deben tener (aproximadamente) las mismas columnas. Esto es similar a lo que ocurre vstacken 'NumPy', como se puede ver en la imagen:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_72.png\">\n",
    "\n",
    "Tener valores duplicados en el índice es malo. Puede encontrarse con varios tipos de problemas (vea el ejemplo de \"eliminación\" a continuación). Incluso si no le importa el índice, intente evitar que tenga valores duplicados en él:\n",
    "\n",
    "- O bien usa 'reset_index=True' argumento\n",
    "\n",
    "- Llamada 'df.reset_index(drop=True)' para reindexar las filas de '0' a 'len(df)-1',\n",
    "\n",
    "- Utilice el keysargumento para resolver la ambigüedad con MultiIndex (ver más abajo).\n",
    "\n",
    "Si las columnas de los DataFrames no coinciden perfectamente entre sí (aquí no cuenta un orden diferente), Pandas puede tomar la intersección de las columnas ( kind='inner’, el valor predeterminado) o insertar NaN para marcar los valores faltantes ( kind='outer'):\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_73.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apilamiento horizontal\n",
    "\n",
    "'concat' También puede realizar apilamiento 'horizontal' (similar 'hstack' a 'NumPy'):\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_74.png\">\n",
    "\n",
    "'join' es más configurable que 'concat': en particular, tiene cinco modos de unión en lugar de solo dos de concat. Consulte la sección \"Unión de relaciones 1:1\" a continuación para obtener más detalles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apilamiento mediante 'MultiIndex'\n",
    "\n",
    "Si las etiquetas de fila y columna coinciden, concatpermite realizar un equivalente 'MultiIndex' de apilamiento vertical (como 'dstack' en 'NumPy'):\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_75.png\">\n",
    "\n",
    "Si la fila y/o las columnas se superponen parcialmente, 'Pandas' alineará los nombres en consecuencia, y probablemente eso no sea lo que desea:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_76.png\">\n",
    "\n",
    "En general, si las etiquetas se superponen, significa que los marcos de datos están relacionados de alguna manera entre sí, y las relaciones entre entidades se describen mejor utilizando la terminología de bases de datos relacionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La relación 1:1\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_77.png\">\n",
    "\n",
    "Esto sucede cuando la información sobre el mismo grupo de objetos se almacena en varios 'DataFrames' diferentes y desea combinarlos en un solo 'DataFrame'.\n",
    "\n",
    "Si la columna que desea fusionar no está en el índice, utilice 'merge'.\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_78.png\">\n",
    "\n",
    "Lo primero que hace es descartar todo lo que se encuentre en el índice. Luego realiza la unión. Por último, renumera los resultados de 0 a n-1.\n",
    "\n",
    "Si la columna ya está en el índice, puedes usar join(que es solo un alias para merge con 'left_index' o 'right_index' establecido en 'True' y diferentes valores predeterminados).\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_79.png\">\n",
    "\n",
    "Como puede ver en este caso simplificado (consulte \"unión externa completa\" más arriba), Pandas es bastante flexible en cuanto a mantener el orden de las filas en comparación con las bases de datos relacionales. Las uniones externas izquierdas y derechas tienden a ser más predecibles que las uniones internas y externas (al menos, hasta que hay valores duplicados en la columna que se va a fusionar). Por lo tanto, si desea un orden de filas garantizado, tendrá que ordenar los resultados de forma explícita o usar 'Categorical Index' ( pdi.lock puede ayudarlo con eso)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La relación 1:n\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_89.png\">\n",
    "\n",
    "Esta es la relación más utilizada en el diseño de bases de datos, donde una fila de la 'tabla A' (por ejemplo, 'Estado') se puede vincular a varias filas de la 'tabla B' (por ejemplo, Ciudad), pero cada fila de la 'tabla B' solo se puede vincular a una fila de la 'tabla A' (una ciudad solo puede estar en un solo estado, pero un estado consta de varias ciudades).\n",
    "\n",
    "Al igual que en las 'relaciones 1:1', para unir un par de tablas relacionadas '1:n' en 'Pandas', tiene dos opciones. Si la columna que se va a fusionar no está en el índice y no tiene problemas en descartar todo lo que esté en el índice de ambas tablas, utilice merge, por ejemplo:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_81.png\">\n",
    "\n",
    "Como ya hemos visto, mergemantiene el orden de las filas de forma menos rigurosa que, por ejemplo, Postgres. La declaración \"preservar el orden de las claves\" de la documentación solo se aplica a left_index=Trueand/or right_index=True(para eso joines un alias) y solo en ausencia de valores duplicados en la columna que se va a fusionar. Por eso mergeand jointiene un sortargumento.\n",
    "\n",
    "Ahora, si la columna a fusionar ya está en el índice del DataFrame correcto, use join(o mergecon right_index=True, que es exactamente lo mismo):\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_82.png\">\n",
    "\n",
    "Esta vez, 'Pandas' mantuvo intactos los valores de índice del marco de datos izquierdo y el orden de las filas.\n",
    "\n",
    "Nota: tenga cuidado, si la segunda tabla tiene valores de índice duplicados, terminará con valores de índice duplicados en el resultado, ¡incluso si el índice de la tabla izquierda es único!\n",
    "\n",
    "A veces, los 'DataFrames' unidos tienen columnas con el mismo nombre. Tanto 'merge' y 'join' tienen una forma de resolver la ambigüedad, pero la sintaxis es ligeramente diferente (además, de forma predeterminada, 'merge' la resolverá con '_x', '_y’ mientras que 'join' generará una excepción), como puede ver en la imagen a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_83.png\">\n",
    "\n",
    "Para resumir:\n",
    "\n",
    "- 'merge' se une a columnas que no son de índice, 'join' requiere que la columna 'derecha' esté indexada;\n",
    "\n",
    "- 'merge'descarta el índice del 'DataFrame izquierdo', 'join' lo conserva;\n",
    "\n",
    "- por defecto, 'merge' realiza un 'inner join', 'join' hace una unión 'left outer';\n",
    "\n",
    "- 'merge' no mantiene el orden de las filas, 'join' las conserva (se aplican algunas restricciones);\n",
    "\n",
    "- 'join' es un alias para 'merge' con 'left_index=True' y/o 'right_index=True'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name  population\n",
      "0    Oslo      698660\n",
      "1  Vienna     1911191\n",
      "\n",
      "     name    area\n",
      "0  Vienna   414.8\n",
      "1   Tokyo  2194.1\n",
      "\n",
      "RELACION 1: (merge)\n",
      "Relación 1:1 'inner join'\n",
      "     name  population   area\n",
      "0  Vienna     1911191  414.8\n",
      "\n",
      "Relación 1:1 'left'\n",
      "     name  population   area\n",
      "0    Oslo      698660    NaN\n",
      "1  Vienna     1911191  414.8\n",
      "\n",
      "Relación 1:1 'outer'\n",
      "     name  population    area\n",
      "0    Oslo    698660.0     NaN\n",
      "1   Tokyo         NaN  2194.1\n",
      "2  Vienna   1911191.0   414.8\n",
      "\n",
      "Relación 1:1 'right'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>population</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>1911191.0</td>\n",
       "      <td>414.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2194.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  population    area\n",
       "0  Vienna   1911191.0   414.8\n",
       "1   Tokyo         NaN  2194.1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# RELACIONES\n",
    "df= pd.DataFrame({'name': ['Oslo', 'Vienna'],\n",
    "              'population':[698660,1911191]\n",
    "    \n",
    "})\n",
    "\n",
    "df1= pd.DataFrame({'name': ['Vienna', 'Tokyo'],\n",
    "                   'area': [414.8, 2194.1]\n",
    "    \n",
    "})\n",
    "\n",
    "cities= pd.DataFrame({'city': ['San Francisco', 'Miami', 'Washington', 'Los Angeles'],\n",
    "                   'state-code': ['CA', 'FL', 'DC', 'CA']\n",
    "    \n",
    "})\n",
    "\n",
    "states= pd.DataFrame({'code': ['CA', 'FL', 'TX'],\n",
    "                     'state': ['California', 'Florida', 'Texas']\n",
    "    \n",
    "})\n",
    "\n",
    "\n",
    "#1:1\n",
    "print(df)\n",
    "print()\n",
    "print(df1)\n",
    "print()\n",
    "print(\"RELACION 1: (merge)\")\n",
    "print(\"Relación 1:1 'inner join'\")\n",
    "print(df.merge(df1, on='name'))\n",
    "print()\n",
    "print(\"Relación 1:1 'left'\")\n",
    "print(df.merge(df1, how='left'))\n",
    "print()\n",
    "print(\"Relación 1:1 'outer'\")\n",
    "print(df.merge(df1, how='outer'))\n",
    "print()\n",
    "print(\"Relación 1:1 'right'\")\n",
    "df.merge(df1, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELACION 1:n\n",
      "            city state-code\n",
      "0  San Francisco         CA\n",
      "1          Miami         FL\n",
      "2     Washington         DC\n",
      "3    Los Angeles         CA\n",
      "\n",
      "  code       state\n",
      "0   CA  California\n",
      "1   FL     Florida\n",
      "2   TX       Texas\n",
      "\n",
      "Relación con 'merge' cuando los códigos de los DataFrame difieren:\n",
      "            city state-code code       state\n",
      "0  San Francisco         CA   CA  California\n",
      "1          Miami         FL   FL     Florida\n",
      "2    Los Angeles         CA   CA  California\n",
      "\n",
      "Filtrando la 'Ciudad' y el 'Estado'\n",
      "            city       state\n",
      "0  San Francisco  California\n",
      "1          Miami     Florida\n",
      "2    Los Angeles  California\n"
     ]
    }
   ],
   "source": [
    "print(\"RELACION 1:n\")\n",
    "print(cities)\n",
    "print()\n",
    "print(states)\n",
    "print()\n",
    "print(\"Relación con 'merge' cuando los códigos de los DataFrame difieren:\")\n",
    "df2= cities.merge(states, left_on= 'state-code', right_on='code')\n",
    "print(df2)\n",
    "print()\n",
    "print(\"Filtrando la 'Ciudad' y el 'Estado'\")\n",
    "print(df2.filter(['city','state']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HACIENDO USO DEL JOIN\n",
      "            city state-code code       state\n",
      "0  San Francisco         CA   CA  California\n",
      "1          Miami         FL   FL     Florida\n",
      "2     Washington         DC   TX       Texas\n",
      "3    Los Angeles         CA  NaN         NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"HACIENDO USO DEL JOIN\")\n",
    "df3= cities.join(states)\n",
    "# Relaciona por los índices\n",
    "print(df3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniones múltiples\n",
    "\n",
    "Como se explicó anteriormente, cuando 'join' se ejecuta contra dos 'DataFrames', por ejemplo 'df.join(df1)', actúa como un alias de 'merge'. Pero 'join' también tiene un modo de \"unión múltiple\", que, a su vez, es un alias de concat(axis=1).\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_84.png\">\n",
    "\n",
    "Este modo es algo limitado en comparación con el modo normal:\n",
    "\n",
    "- no proporciona un medio para la resolución de columnas duplicadas;\n",
    "\n",
    "- Sólo funciona para 'relaciones 1:1' (uniones de índice a índice).\n",
    "\n",
    "Por lo tanto, se supone que varias 'relaciones 1:n' se deben unir una por una. El repositorio 'pandas-illustrated' también tiene una herramienta para eso, como puede ver a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_85.png\">\n",
    "\n",
    "'pdi.join' es un contenedor simple 'join' que acepta listas en argumentos 'on', 'how' y 'suffixes'  para que puedas hacer varias uniones en un comando. Al igual que con la unión original, 'on' las columnas pertenecen al 0 primer DataFrame0  y los demás 'DataFrames' se unen en función de sus índices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserta y elimina\n",
    "\n",
    "Dado que un 'DataFrame' es una colección de columnas, es más fácil aplicar estas operaciones a las filas que a las columnas. Por ejemplo, la inserción de una columna siempre se realiza en el lugar, mientras que la inserción de una fila siempre da como resultado un nuevo 'DataFrame', como se muestra a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_86.png\">\n",
    "\n",
    "Eliminar columnas normalmente no genera preocupaciones, excepto que del df['D']funciona mientras del 'df.D' no funciona (limitación en el nivel de Python).\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_87.png\">\n",
    "\n",
    "Eliminar filas con 'drop' es sorprendentemente lento y puede generar errores complejos si las etiquetas sin procesar no son únicas. Por ejemplo:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_88.png\">\n",
    "\n",
    "Una solución sería utilizar 'ignore_index=True', que indica 'concat' que se deben restablecer los nombres de las filas después de la concatenación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_90.png\">\n",
    "\n",
    "En este caso, namesería útil configurar la columna como índice, pero no así para filtros más complejos.\n",
    "\n",
    "Otra solución rápida, universal e incluso que funciona con nombres de filas duplicados es utilizar la indexación en lugar de la eliminación. Puede negar la condición manualmente o utilizar una automatización (de una sola línea) de la biblioteca \"pdi\":\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_91.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### groupby\n",
    "\n",
    "Esta operación ya se ha descrito en detalle en la sección 'Series', pero 'DataFrame' 'groupby' tiene un par de trucos específicos además de eso.\n",
    "\n",
    "Primero, puedes especificar la columna a agrupar usando solo un nombre, como se muestra en la siguiente imagen:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_92.png\">\n",
    "\n",
    "Sin 'as_index=False', Pandas convierte la columna por la que se realizó la agrupación en la columna de índice. Si esto no es deseable, puede utilizar 'reset_index()' o especificar 'as_index=False'.\n",
    "\n",
    "Por lo general, hay más columnas en el DataFrame de las que desea ver en el resultado. De manera predeterminada, Pandas suma todo lo que sea remotamente sumable, por lo que deberá limitar su elección, como se muestra a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_93.png\">\n",
    "\n",
    "Tenga en cuenta que, al sumar sobre una sola columna, obtendrá una serie en lugar de un DataFrame. Si, por algún motivo, desea un DataFrame, puede:\n",
    "\n",
    "- Utilice corchetes dobles: 'df.groupby('product')[['quantity']].sum()' o\n",
    "\n",
    "- convertir explícitamente: 'df.groupby('product')['quantity'].sum().to_frame()'\n",
    "\n",
    "Cambiar al índice numérico también lo convertirá en un DataFrame:\n",
    "\n",
    "- 'df.groupby('product', as_index=False)['quantity'].sum()' o\n",
    "\n",
    "- 'df.groupby('product')['quantity'].sum().reset_index()'\n",
    "\n",
    "Pero a pesar de la apariencia inusual, en muchos casos una Serie se comporta igual que un DataFrame, por lo que tal vez un \"lavado de cara\" 'pdi.patch_series_repr()'sería suficiente.\n",
    "\n",
    "A veces, las distintas columnas deben tratarse de forma diferente cuando se agrupan. Por ejemplo, está perfectamente bien sumar sobre la cantidad, pero no tiene sentido sumar sobre el precio. El uso de '.agg' permite especificar distintas funciones de agregación para distintas columnas, como se muestra en la imagen:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_94.png\">\n",
    "\n",
    "O bien, puede crear varias funciones de agregación para una sola columna:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_95.png\">\n",
    "\n",
    "O bien, para evitar el engorroso cambio de nombre de columnas, puede hacer lo siguiente:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_96.png\">\n",
    "\n",
    "A veces, las funciones predefinidas no son lo suficientemente buenas para producir los resultados requeridos. Por ejemplo, sería mejor usar pesos al promediar el precio. Por lo tanto, puede proporcionar una función personalizada para eso. A diferencia de Series, la función puede acceder a varias columnas del grupo (se le proporciona un submarco de datos como argumento), como se muestra a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_97.png\">\n",
    "\n",
    "Lamentablemente, no se pueden combinar agregados predefinidos con funciones personalizadas de varias columnas, como la anterior, en un solo comando, ya que aggsolo acepta funciones de usuario de una sola columna. Lo único a lo que pueden acceder las funciones de usuario de una sola columna es el índice, que puede resultar útil en determinadas situaciones. Por ejemplo, ese día, se vendieron plátanos con un descuento del 50 %, como se puede ver a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_98.png\">\n",
    "\n",
    "Para acceder al valor del grupo por columna desde la función personalizada, se incluyó previamente en el índice.\n",
    "\n",
    "Como es habitual, la función menos personalizada ofrece el mejor rendimiento. Por lo tanto, en orden de velocidad creciente:\n",
    "\n",
    "- Función personalizada de varias columnas a través 'deg.apply()'\n",
    "\n",
    "- Función personalizada de una sola columna a través de 'g.agg()' (admite aceleración con Cython o Numba)\n",
    "\n",
    "- funciones predefinidas (objeto de función 'Pandas' o 'NumPy', o su nombre como cadena).\n",
    "\n",
    "Una herramienta útil para mirar los datos desde una perspectiva diferente, a menudo utilizada junto con la agrupación, son las tablas dinámicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   client  product  quantity  price  total\n",
      "0    John  bananas         5      2     10\n",
      "1  Silvia  oranges         3      5     15\n",
      "2  Andrew  bananas         4      3     12\n",
      "\n",
      "Sumando por productos:\n",
      "         quantity  total\n",
      "product                 \n",
      "bananas         9     22\n",
      "oranges         3     15\n",
      "\n",
      "Usando el metodo 'agg' para calcular 'suma', 'max' y 'mean'\n",
      "        quantity price         \n",
      "             sum   max min mean\n",
      "product                        \n",
      "bananas        9     3   2  2.5\n",
      "oranges        3     5   5  5.0\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de 'groupby'Archivos\n",
    "data= {'client':['John','Silvia','Andrew'],\n",
    "     'product':['bananas','oranges','bananas'],\n",
    "     'quantity':[5, 3, 4],\n",
    "     'price':[2, 5, 3],\n",
    "     'total':[10, 15, 12]\n",
    "}\n",
    "\n",
    "df= pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(\"Sumando por productos:\")\n",
    "print(df.groupby('product')[['quantity','total']].sum())\n",
    "print()\n",
    "print(\"Usando el metodo 'agg' para calcular 'suma', 'max' y 'mean'\")\n",
    "print(df.groupby('product').agg({'quantity':'sum', 'price':['max', 'min', 'mean']}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pivotar y despivotar\n",
    "\n",
    "Supongamos que tiene una variable aque depende de dos parámetros 'i' y 'j'. Hay dos formas equivalentes de representarla como tabla:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_99.png\">\n",
    "\n",
    "El formato \"ancho\" (wide format) es más apropiado cuando los datos son \"densos\" (cuando hay pocos elementos cero o faltantes), y el \"largo\" (long format) es mejor cuando los datos son \"dispersos\" (la mayoría de los elementos son ceros o faltantes y se pueden omitir de la tabla). La situación se complica cuando hay más de dos parámetros.\n",
    "\n",
    "Naturalmente, debería haber una forma sencilla de realizar la conversión entre esos formatos, y Pandas ofrece una solución sencilla y cómoda para ello: la tabla dinámica.\n",
    "\n",
    "Como ejemplo menos abstracto, considere la siguiente tabla con los datos de ventas. Dos clientes han comprado la cantidad designada de dos tipos de productos. Inicialmente, estos datos están en \"formato largo\". Para convertirlos al \"formato ancho\", utilice: 'df.pivot'\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_100.png\">\n",
    "\n",
    "Este comando descarta todo lo que no esté relacionado con la operación (es decir, columnas de índice y precio) y transforma la información de las tres columnas solicitadas al formato largo, colocando los nombres de los clientes en el índice del resultado, los títulos de los productos en sus columnas y la cantidad vendida en el \"cuerpo\" del mismo.\n",
    "\n",
    "En cuanto a la operación inversa, puedes utilizar stack. Combina 'index' y 'columns' en 'MultiIndex':\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_101.png\">\n",
    "\n",
    "Si solo desea 'stack' determinadas columnas, puede utilizar 'melt':\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_102.png\">\n",
    "\n",
    "Tenga en cuenta que meltordena las filas del resultado de manera diferente.\n",
    "\n",
    "'pivot' pierde la información sobre el nombre del 'cuerpo' del resultado, por lo que con ambos 'stack' tenemos 'melt' que 'recordarle' a Pandas el nombre de la columna 'cantidad'.\n",
    "\n",
    "En el ejemplo anterior, todos los valores están presentes, pero no es obligatorio:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_103.png\">\n",
    "\n",
    "La práctica de agrupar valores y luego pivotear los resultados es tan común que 'groupby' se pivothan agrupado en una función dedicada (y un método 'DataFrame' correspondiente) 'pivot_table':\n",
    "\n",
    "- Sin el argumento 'columns', se comporta de manera similar a 'groupby';\n",
    "\n",
    "- cuando no hay filas duplicadas para agrupar, funciona igual que pivot;\n",
    "\n",
    "- De lo contrario, realiza agrupación y pivoteo.\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_104.png\">\n",
    "\n",
    "El parámetro 'aggfunc' controla qué función de agregación se debe utilizar para agrupar las filas ( meanpor defecto).\n",
    "\n",
    "Para mayor comodidad, 'pivot_table' puede calcular los subtotales y el total general:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_105.png\">\n",
    "\n",
    "Una vez creada, una tabla dinámica se convierte en un simple 'DataFrame' normal, por lo que se puede consultar utilizando los métodos estándar descritos anteriormente:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_106.png\">\n",
    "\n",
    "La mejor manera de entenderlo 'pivot_table' (¡además de empezar a usarlo de inmediato!) es seguir un estudio de caso relevante. Recomiendo encarecidamente dos de ellos:\n",
    "\n",
    "- En esta entrada del blog se describe un caso de venta extremadamente completo.\n",
    "\n",
    "- Un caso de uso genérico muy bien escrito (basado en el infame conjunto de datos del Titanic)\n",
    "\n",
    "Las tablas dinámicas son especialmente útiles cuando se utilizan con 'MultiIndex'. Hemos visto muchos ejemplos en los que las funciones de 'Pandas' devuelven un 'DataFrame' con múltiples índices. Veámoslo con más detalle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Original\n",
      "   client  product  quantity  price  total\n",
      "0    John  bananas         5      2     10\n",
      "1  Silvia  oranges         3      5     15\n",
      "2  Andrew  bananas         4      3     12\n",
      "\n",
      "Aplicando el método 'stack'\n",
      "0  client         John\n",
      "   product     bananas\n",
      "   quantity          5\n",
      "   price             2\n",
      "   total            10\n",
      "1  client       Silvia\n",
      "   product     oranges\n",
      "   quantity          3\n",
      "   price             5\n",
      "   total            15\n",
      "2  client       Andrew\n",
      "   product     bananas\n",
      "   quantity          4\n",
      "   price             3\n",
      "   total            12\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PIVOTEANDO EL DATAFRAME\n",
    "data= {'client':['John','Silvia','Andrew'],\n",
    "     'product':['bananas','oranges','bananas'],\n",
    "     'quantity':[5, 3, 4],\n",
    "     'price':[2, 5, 3],\n",
    "     'total':[10, 15, 12]\n",
    "}\n",
    "df= pd.DataFrame(data)\n",
    "print(\"DataFrame Original\") \n",
    "print(df)\n",
    "print()\n",
    "print(\"Aplicando el método 'stack'\")\n",
    "print(df.stack())\n",
    "print()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   client  product  quantity  price  total\n",
      "0    John  bananas         5      2     10\n",
      "1  Silvia  oranges         3      5     15\n",
      "2  Andrew  bananas         4      3     12\n",
      "\n",
      "Creando con el método 'pivot' una tabla dinámica\n",
      "usando como índice: 'client', las columnas: 'product' y values: 'quantity'\n",
      "product  bananas  oranges\n",
      "client                   \n",
      "Andrew       4.0      NaN\n",
      "John         5.0      NaN\n",
      "Silvia       NaN      3.0\n",
      "\n",
      "Usando 'melt' para reorganizar el DataFrame\n",
      "   client  product measurement  value\n",
      "0    John  bananas    quantity      5\n",
      "1  Silvia  oranges    quantity      3\n",
      "2  Andrew  bananas    quantity      4\n",
      "3    John  bananas       price      2\n",
      "4  Silvia  oranges       price      5\n",
      "5  Andrew  bananas       price      3\n",
      "6    John  bananas       total     10\n",
      "7  Silvia  oranges       total     15\n",
      "8  Andrew  bananas       total     12\n"
     ]
    }
   ],
   "source": [
    "# USANDO PIVOT\n",
    "print(df)\n",
    "print()\n",
    "print(\"Creando con el método 'pivot' una tabla dinámica\")\n",
    "print(\"usando como índice: 'client', las columnas: 'product' y values: 'quantity'\")\n",
    "print(df.pivot(index='client', columns='product', values='quantity'))\n",
    "print()\n",
    "print(\"Usando 'melt' para reorganizar el DataFrame\")\n",
    "df_melted = df.melt(id_vars=['client', 'product'], value_vars=['quantity', 'price', 'total'], var_name='measurement', value_name='value')\n",
    "print(df_melted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4. Multiíndice\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_107.png\">\n",
    "\n",
    "El uso más sencillo de 'MultiIndex' para las personas que nunca han oído hablar de Pandas es utilizar una segunda columna de índice como complemento de la primera para identificar cada fila de forma única. Por ejemplo, para desambiguar ciudades de diferentes estados, el nombre del estado suele añadirse al nombre de la ciudad. (¿Sabías que hay alrededor de 40 Springfields en los EE. UU.?) En las bases de datos relacionales, se denomina clave principal compuesta.\n",
    "\n",
    "Puede especificar las columnas que se incluirán en el índice después de analizar el 'DataFrame' desde 'CSV' o inmediatamente como argumento de 'read_csv'.\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_108.png\">\n",
    "\n",
    "También puedes agregar niveles existentes al 'MultiIndex' posteriormente usando 'append=True', como puedes ver en la imagen a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_109.png\">\n",
    "\n",
    "Otro caso de uso, más típico de 'Pandas', es la representación de múltiples dimensiones en una situación en la que se dispone de una serie de objetos con un determinado conjunto de propiedades, especialmente cuando evolucionan con el tiempo. Por ejemplo:\n",
    "\n",
    "- resultados de una encuesta sociológica,\n",
    "\n",
    "- El conjunto de datos del 'Titanic',\n",
    "\n",
    "- observaciones meteorológicas históricas,\n",
    "\n",
    "- Una cronología de la clasificación del campeonato.\n",
    "\n",
    "Esto también se conoce como 'Panel data' y Pandas debe su nombre a ello.\n",
    "\n",
    "Agreguemos tal dimensión:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_110.png\">\n",
    "\n",
    "Ahora tenemos un espacio de cuatro dimensiones, donde\n",
    "\n",
    "- Los años forman una dimensión (casi continua),\n",
    "\n",
    "- Los nombres de las ciudades se colocan a lo largo del segundo,\n",
    "\n",
    "- nombres de estados a lo largo del tercero, y\n",
    "\n",
    "- Las propiedades particulares de la ciudad ('población', 'densidad', 'área', etc.) actúan como 'marcas de verificación' a lo largo de la cuarta dimensión.\n",
    "\n",
    "El siguiente diagrama ilustra el concepto:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_111.png\">\n",
    "\n",
    "Para dejar espacio para los nombres de las dimensiones correspondientes a las columnas, Pandas desplaza todo el encabezado hacia arriba:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_112.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city     state  population   area\n",
      "0     Portland    Oregon      609456  345.7\n",
      "1  Springfield  Illinois      117006  158.4\n",
      "2     Portland     Maine       66318   55.8\n",
      "3  Springfield    Oregon       60177   41.1\n",
      "\n",
      "Indice= 'city'\n",
      "                state  population   area\n",
      "city                                    \n",
      "Portland       Oregon      609456  345.7\n",
      "Springfield  Illinois      117006  158.4\n",
      "Portland        Maine       66318   55.8\n",
      "Springfield    Oregon       60177   41.1\n",
      "\n",
      "Indice= 'city' y 'state'\n",
      "                      population   area\n",
      "city        state                      \n",
      "Portland    Oregon        609456  345.7\n",
      "Springfield Illinois      117006  158.4\n",
      "Portland    Maine          66318   55.8\n",
      "Springfield Oregon         60177   41.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv(\"Archivos/cities-states.csv\")\n",
    "print(df)\n",
    "print()\n",
    "print(\"Indice= 'city'\")\n",
    "df= pd.read_csv(\"Archivos/cities-states.csv\", index_col=('city'))\n",
    "print(df)\n",
    "df= pd.read_csv(\"Archivos/cities-states.csv\", index_col=('city','state'))\n",
    "print()\n",
    "print(\"Indice= 'city' y 'state'\")\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      population  density\n",
      "city        state                        \n",
      "Portland    Oregon        583776   1688.7\n",
      "Springfield Illinois      116250    733.9\n",
      "Portland    Maine          66194   1186.3\n",
      "Springfield Oregon         59403   1445.3\n",
      "\n",
      "                      population  density\n",
      "city        state                        \n",
      "Portland    Oregon        652503   1887.5\n",
      "Springfield Illinois      114394    722.2\n",
      "Portland    Maine          68408   1225.9\n",
      "Springfield Oregon         61851   1504.9\n",
      "\n",
      "                           2010               2020        \n",
      "                     population density population density\n",
      "city        state                                         \n",
      "Portland    Oregon       583776  1688.7     652503  1887.5\n",
      "Springfield Illinois     116250   733.9     114394   722.2\n",
      "Portland    Maine         66194  1186.3      68408  1225.9\n",
      "Springfield Oregon        59403  1445.3      61851  1504.9\n",
      "\n",
      "year                       2010               2020        \n",
      "property             population density population density\n",
      "city        state                                         \n",
      "Portland    Oregon       583776  1688.7     652503  1887.5\n",
      "Springfield Illinois     116250   733.9     114394   722.2\n",
      "Portland    Maine         66194  1186.3      68408  1225.9\n",
      "Springfield Oregon        59403  1445.3      61851  1504.9\n"
     ]
    }
   ],
   "source": [
    "df1= pd.read_csv(\"Archivos/stats2010.csv\", index_col=('city','state'))\n",
    "df2= pd.read_csv(\"Archivos/stats2020.csv\", index_col=('city','state'))\n",
    "\n",
    "print(df1)\n",
    "print()\n",
    "print(df2)\n",
    "print()\n",
    "\n",
    "df3= pd.concat([df1,df2], axis= 1, keys= [2010, 2020])\n",
    "\n",
    "print(df3)\n",
    "\n",
    "print()\n",
    "\n",
    "df4= df3.rename_axis(['year','property'], axis= 1)\n",
    "\n",
    "print(df4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupamiento aparente\n",
    "\n",
    "Lo primero que hay que tener en cuenta sobre MultiIndex es que no agrupa nada, como podría parecer. Internamente, es solo una secuencia plana de etiquetas, como se puede ver a continuación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(2010, 'population'),\n",
       "            (2010,    'density'),\n",
       "            (2020, 'population'),\n",
       "            (2020,    'density')],\n",
       "           names=['year', 'property'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes obtener el mismo groupbyefecto para las etiquetas de fila simplemente ordenándolas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">2010</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>density</th>\n",
       "      <th>population</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Portland</th>\n",
       "      <th>Maine</th>\n",
       "      <td>66194</td>\n",
       "      <td>1186.3</td>\n",
       "      <td>68408</td>\n",
       "      <td>1225.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>583776</td>\n",
       "      <td>1688.7</td>\n",
       "      <td>652503</td>\n",
       "      <td>1887.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Springfield</th>\n",
       "      <th>Illinois</th>\n",
       "      <td>116250</td>\n",
       "      <td>733.9</td>\n",
       "      <td>114394</td>\n",
       "      <td>722.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>59403</td>\n",
       "      <td>1445.3</td>\n",
       "      <td>61851</td>\n",
       "      <td>1504.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           2010               2020        \n",
       "                     population density population density\n",
       "city        state                                         \n",
       "Portland    Maine         66194  1186.3      68408  1225.9\n",
       "            Oregon       583776  1688.7     652503  1887.5\n",
       "Springfield Illinois     116250   733.9     114394   722.2\n",
       "            Oregon        59403  1445.3      61851  1504.9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluso puedes desactivar la agrupación visual por completo configurando la opción de Pandas correspondiente : 'pd.options.display.multi_sparse=False'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversiones de tipos\n",
    "\n",
    "Pandas (así como el propio Python) hace una diferencia entre números y cadenas, por lo que suele ser una buena idea convertir números en cadenas en caso de que el tipo de datos no se haya detectado automáticamente:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_113.png\">\n",
    "\n",
    "Si te sientes aventurero, puedes hacer lo mismo con herramientas estándar:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_114.png\">\n",
    "\n",
    "Pero para usarlos correctamente, es necesario comprender qué son los \"niveles\" y los \"códigos\", mientras que 'pdi' permite trabajar con MultiIndex como si los niveles fueran listas ordinarias o matrices 'NumPy'.\n",
    "\n",
    "Si realmente te lo preguntas, 'niveles' y 'códigos' son algo en lo que se divide una lista regular de etiquetas de un cierto nivel para acelerar operaciones como pivot, joiny así sucesivamente:\n",
    "\n",
    "- pdi.get_level(df, 0) == Int64Index([2010, 2010, 2020, 2020])\n",
    "\n",
    "- df.columns.levels[0] == Int64Index([2010, 2020])\n",
    "\n",
    "- df.columns.codes[0] == Int64Index([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creación de un DataFrame con un MultiIndex\n",
    "\n",
    "Además de leer archivos CSV y crear a partir de las columnas existentes, existen otros métodos para crear un MultiIndex. Se utilizan con menos frecuencia, principalmente para realizar pruebas y depurar errores.\n",
    "\n",
    "La forma más intuitiva de utilizar la propia representación de MultiIndex de Panda no funciona por razones históricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Must pass both levels and codes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2010\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpopulation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2010\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdensity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m               \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2020\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpopulation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2020\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdensity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m              \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproperty\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\REY\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:340\u001b[0m, in \u001b[0;36mMultiIndex.__new__\u001b[1;34m(cls, levels, codes, sortorder, names, dtype, copy, name, verify_integrity)\u001b[0m\n\u001b[0;32m    338\u001b[0m     names \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m levels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m codes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass both levels and codes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(levels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(codes):\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of levels and codes must be the same.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Must pass both levels and codes"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.MultiIndex([('2010','population'),\n",
    "               ('2010','density'),\n",
    "               ('2020','population'),\n",
    "               ('2020','density')],\n",
    "              names= ['year','property'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los 'niveles' y 'códigos' aquí se consideran (hoy en día) detalles de implementación que no deberían exponerse al usuario final, pero tenemos lo que tenemos.\n",
    "\n",
    "Probablemente, la forma más sencilla de construir un MultiIndex es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df= pd.DataFrame(np.zeros((3, 4), int),\n",
      "\n",
      "        index= [['a','a','b'],\n",
      "                ['c','d','c']],\n",
      "\n",
      "      columns= [['A','A','B','B'],\n",
      "                ['C','D','C','D']])\n",
      "\n",
      "     A     B   \n",
      "     C  D  C  D\n",
      "a c  0  0  0  0\n",
      "  d  0  0  0  0\n",
      "b c  0  0  0  0\n",
      "\n",
      "df1= pd.DataFrame(np.zeros((3, 4), int))\n",
      "   0  1  2  3\n",
      "0  0  0  0  0\n",
      "1  0  0  0  0\n",
      "2  0  0  0  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df= pd.DataFrame(\n",
    "                 np.zeros((3, 4), int),\n",
    "                 index= [['a','a','b'],\n",
    "                         ['c','d','c']],\n",
    "                 columns= [['A','A','B','B'],\n",
    "                           ['C','D','C','D']])\n",
    "\n",
    "print(\"df= pd.DataFrame(np.zeros((3, 4), int),\\n\\n        index= [['a','a','b'],\\n                ['c','d','c']],\\n\\n      columns= [['A','A','B','B'],\\n                ['C','D','C','D']])\")\n",
    "print()\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "df1= pd.DataFrame(np.zeros((3, 4), int))\n",
    "\n",
    "df2= index= [['a','a','b'],\n",
    "             ['c','d','c']],\n",
    "\n",
    "columns= [['A','A','B','B'],\n",
    "              ['C','D','C','D']]\n",
    "\n",
    "\n",
    "print(\"df1= pd.DataFrame(np.zeros((3, 4), int))\")\n",
    "print(df1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metodo chaining\n",
      "M    A     B   \n",
      "N    C  D  C  D\n",
      "K L            \n",
      "a c  0  0  0  0\n",
      "  d  0  0  0  0\n",
      "b c  0  0  0  0\n",
      "\n",
      "df.index.names = ['K','L']\n",
      "df.column.names = ['M','N']\n"
     ]
    }
   ],
   "source": [
    "print(\"Metodo chaining\")\n",
    "df= df.rename_axis(['K','L'], axis=0).rename_axis(['M','N'], axis=1)\n",
    "print(df)\n",
    "print()\n",
    "print(\"df.index.names = ['K','L']\")\n",
    "print(\"df.column.names = ['M','N']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La desventaja es que los nombres de los niveles deben asignarse en una línea separada o en un método encadenado independiente. Varios constructores alternativos agrupan los nombres junto con las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDIANTE ARREGLOS\n",
      "MultiIndex([('a', 'd'),\n",
      "            ('b', 'e'),\n",
      "            ('c', 'f')],\n",
      "           names=['K', 'L'])\n",
      "\n",
      "      A   B\n",
      "K L        \n",
      "a d  10  20\n",
      "b e  30  40\n",
      "c f  50  60\n",
      "\n",
      "MEDIANTE TUPLAS\n",
      "MultiIndex([('a', 'd'),\n",
      "            ('b', 'e'),\n",
      "            ('c', 'f')],\n",
      "           names=['K', 'L'])\n",
      "\n",
      "      A   B\n",
      "K L        \n",
      "a d  10  20\n",
      "b e  30  40\n",
      "c f  50  60\n",
      "\n",
      "MEDIANTE DICCIONARIO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndf2= pd.DataFrame({'A':[10, 20, 30], 'B':[40, 50, 60]},\\n                  index= pdi.from_dict({'K':['a','b','c'],\\n                                       'L':['d','e','f']}))\\n\\nprint(df2)\\n\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"MEDIANTE ARREGLOS\")\n",
    "mi= pd.MultiIndex.from_arrays([['a','b','c'], ['d','e','f']], names=['K','L'])\n",
    "print(mi)\n",
    "print()\n",
    "\n",
    "df= pd.DataFrame([[10, 20],[30, 40],[50, 60]],\n",
    "                 index= mi,\n",
    "                 columns= ['A','B'])\n",
    "print(df)\n",
    "print()\n",
    "print(\"MEDIANTE TUPLAS\")\n",
    "mi= pd.MultiIndex.from_tuples([('a','d'),('b','e'), ('c','f')], names=['K','L'])\n",
    "print(mi)\n",
    "print()\n",
    "df1= pd.DataFrame([[10, 20],[30, 40],[50, 60]],\n",
    "                 index= mi,\n",
    "                 columns= ['A','B'])\n",
    "print(df1)\n",
    "print()\n",
    "print(\"MEDIANTE DICCIONARIO\")\n",
    "\"\"\"\n",
    "df2= pd.DataFrame({'A':[10, 20, 30], 'B':[40, 50, 60]},\n",
    "                  index= pdi.from_dict({'K':['a','b','c'],\n",
    "                                       'L':['d','e','f']}))\n",
    "\n",
    "print(df2)\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando los niveles forman una estructura regular, puedes especificar los elementos clave y dejar que Pandas los intercale automáticamente, como se muestra a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_115.png\">\n",
    "\n",
    "Todos los métodos enumerados anteriormente también se aplican a las columnas. Por ejemplo:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_116.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexación con MultiIndex\n",
    "\n",
    "Lo bueno de acceder a 'DataFrame' a través de 'MultiIndex' es que puedes referenciar fácilmente todos los niveles a la vez (omitiendo potencialmente los niveles internos) con una sintaxis agradable y familiar.\n",
    "\n",
    "Columnas — mediante corchetes regulares\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_117.png\">\n",
    "\n",
    "Filas y celdas: uso.loc[]\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_118.png\">\n",
    "\n",
    "Ahora bien, ¿qué sucede si desea seleccionar todas las ciudades de Oregón o dejar solo las columnas con población? La sintaxis de Python impone dos limitaciones:\n",
    "\n",
    "1. No hay forma de distinguir entre ambos 'df['a', 'b']' y 'df[('a', 'b')]': se procesa de la misma manera, por lo que no puedes escribir simplemente 'df[:, 'Oregon']'. De lo contrario, Pandas nunca sabría si te refieres a Oregon la columna o Oregon el segundo nivel de filas.\n",
    "\n",
    "2. Python solo permite dos puntos dentro de corchetes, no dentro de paréntesis, por lo que no puedes escribir 'df.loc[(:, 'Oregon'), :]'.\n",
    "\n",
    "Desde el punto de vista técnico, no es difícil organizarlo. He parcheado el DataFrame (es decir, he creado un parche que se descarta cuando el núcleo muere) para agregar esa funcionalidad, que puedes ver aquí:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_119.png\">\n",
    "\n",
    "La única desventaja de esta sintaxis es que cuando se utilizan ambos indexadores, devuelve una copia, por lo que no se puede escribir 'df.mi[:,’Oregon’].co[‘population’] = 10'. Hay muchos indexadores alternativos, algunos de los cuales permiten este tipo de asignaciones, pero todos tienen sus propias peculiaridades:\n",
    "\n",
    "1. Puedes intercambiar capas internas con capas externas y usar los corchetes.\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_120.png\">\n",
    "\n",
    "Por lo tanto, 'df[:, ‘population’]' se puede implementar con\n",
    "'df.swaplevel(axis=1)['population']'\n",
    "\n",
    "Esto parece extraño y no es conveniente para más de dos niveles.\n",
    "\n",
    "2. Puedes utilizar el método 'xs':\n",
    "'df.xs(‘population’, level=1, axis=1)'.\n",
    "\n",
    "No parece lo suficientemente Python, especialmente cuando se seleccionan varios niveles.\n",
    "Este método no puede filtrar filas y columnas al mismo tiempo, por lo que el motivo del nombre 'xs'(que significa \"sección transversal\") no está del todo claro. No se puede utilizar para establecer valores.\n",
    "\n",
    "3. El método preferido para manejar esta situación es crear un alias para pd.IndexSlicey usarlo dentro de '.loc':\n",
    "'idx=pd.IndexSlice; df.loc[:, idx[:, 'population']]'\n",
    "\n",
    "Eso es más Python, pero la necesidad de crear un alias para acceder a un elemento es algo complicado (y es demasiado largo sin un alias). Puedes seleccionar filas y columnas al mismo tiempo. Escribible.\n",
    "\n",
    "4. Puedes aprender a utilizar sliceen lugar de dos puntos. Si lo sabes, 'a[3:10:2] == a[slice(3,10,2)]'  es posible que también entiendas lo siguiente: 'df.loc[:, (slice(None), 'population')]', pero de todos modos es difícil de leer. Puede seleccionar filas y columnas al mismo tiempo. Es escribible.\n",
    "\n",
    "En resumen, Pandas tiene varias formas de acceder a elementos del DataFrame con MultiIndex usando corchetes, pero ninguna de ellas es lo suficientemente conveniente, por lo que tuvieron que adoptar una sintaxis de indexación alternativa:\n",
    "\n",
    "5. Un mini-lenguaje para el .querymétodo (es el único que es capaz de hacer 'o', no sólo 'y'):\n",
    "'df.query('state==\"Oregon\" or city==\"Portland\"')'.\n",
    "\n",
    "Es conveniente y rápido, pero carece de soporte de IDE (no tiene autocompletado, resaltado de sintaxis, etc.) y solo filtra las filas, no las columnas. Eso significa que no se puede implementar 'df[:, 'population']' sin transponer el DataFrame (que perderá los tipos a menos que todas las columnas sean del mismo tipo). No se puede escribir.\n",
    "\n",
    "A continuación se muestra una tabla resumen de todos los métodos de indexación MultiIndex:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_121.png\">\n",
    "\n",
    "Ninguno de ellos es perfecto, pero algunos se acercan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking and unstacking \n",
    "\n",
    "Pandas no tiene columnas 'set_index'. Una forma habitual de agregar niveles a las columnas es \"desapilar\" los niveles existentes del índice:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_122.png\">\n",
    "\n",
    "El sistema 'stack' de Pandas es muy diferente al 'stack'vde NumPy. Veamos qué dice la documentación sobre las convenciones de nombres:\n",
    "\n",
    "“La función recibe su nombre por analogía con una colección de libros que se reorganizan desde estar uno al lado del otro en una posición horizontal (las columnas del marco de datos) a estar apilados verticalmente uno sobre el otro (en el índice del marco de datos)”.\n",
    "\n",
    "La parte \"on top\" no me suena muy convincente, pero al menos esta explicación ayuda a memorizar cuál mueve las cosas en qué dirección. Por cierto, Series tiene 'unstack', pero no tiene 'stack' porque ya está \"apilada\". Al ser unidimensional, Series puede actuar como vector de fila o vector de columna en diferentes situaciones, pero normalmente se las considera vectores de columna (por ejemplo, columnas de marcos de datos).\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_123.png\">\n",
    "\n",
    "También puede especificar qué nivel apilar o desapilar por nombre o por índice posicional. En este ejemplo, df.stack(), df.stack(1)y df.stack(‘year’)producen el mismo resultado, así como df1.unstack(), df1.unstack(2), y df1.unstack(‘year’). El destino siempre es \"después del último nivel\" y no es configurable. Si necesita colocar el nivel en otro lugar, puede usar df.swaplevel().sort_index()opdi.swap_level(df, sort=True)\n",
    "\n",
    "No debe 'columns' contener valores duplicados para ser elegible para apilar (lo mismo se aplica para indexdesapilar):\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_124.png\">\n",
    "\n",
    "También puede especificar qué nivel apilar o desapilar por nombre o por índice posicional. En este ejemplo, 'df.stack()', 'df.stack(1)' y 'df.stack(‘year’)' producen el mismo resultado, así como 'df1.unstack()', 'df1.unstack(2)', y 'df1.unstack(‘year’)'. El destino siempre es \"después del último nivel\" y no es configurable. Si necesita colocar el nivel en otro lugar, puede usar 'df.swaplevel().sort_index()opdi.swap_level(df, sort=True)'\n",
    "\n",
    "No debe 'columns' contener valores duplicados para ser elegible para 'apilar' (lo mismo se aplica para 'index' para 'desapilar'):\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_126.png\">\n",
    "\n",
    "Se podría especular que si el lunes de 'John' está a la izquierda del viernes de 'John', entonces ‘Mon’ < ‘Fri’, y de manera similar, ‘Fri’ < ‘Sun’ para Silvia, por lo que el resultado debería ser ‘Mon’ < ‘Fri’ < ‘Sun’. Esto es legítimo, pero ¿qué pasa si las columnas restantes están en un orden diferente, digamos, ‘Mon’ < ‘Fri’y ‘Tue’ < ‘Fri'? O ‘Mon’ < ‘Fri’y ‘Wed’ < ‘Sat’?\n",
    "\n",
    "Vale, no hay tantos días de la semana y Pandas podría deducir el orden basándose en el conocimiento previo. Pero la humanidad no ha llegado a una conclusión decisiva sobre si el domingo debería estar al final o al principio de la semana. ¿Qué orden debería utilizar Pandas por defecto? ¿Leer configuraciones regionales? ¿Y qué pasa con secuencias menos triviales, por ejemplo, el orden de los estados de los EE.UU.?\n",
    "\n",
    "Lo que hace Pandas en esta situación es simplemente ordenarlo alfabéticamente, como puedes ver a continuación:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_127.png\">\n",
    "\n",
    "Aunque se trata de una opción predeterminada sensata, sigue pareciendo incorrecta. ¡Debería haber una solución! Y la hay. Se llama 'CategoricalIndex'. Recuerda el orden incluso si faltan algunas etiquetas. Recientemente se ha integrado sin problemas en la cadena de herramientas de Pandas. Lo único que le falta es infraestructura. Es difícil de construir; es frágil (recurre al tipo de datos de objeto en ciertas operaciones), pero es perfectamente utilizable y la biblioteca 'pdi' tiene algunos ayudantes para acentuar la curva de aprendizaje.\n",
    "\n",
    "Por ejemplo, para indicarle a Pandas que bloquee el orden de, digamos, un índice simple que contiene los productos (que inevitablemente se ordenarán si decides desapilar los días de la semana en columnas), necesitas escribir algo tan horrendo como 'df.index = pd.CategoricalIndex(df.index, df.index, sorted=True)'. Y es mucho más artificial para 'MultiIndex'.\n",
    "\n",
    "La biblioteca 'pdi' tiene una función auxiliar 'locked' (y un alias 'lock' que tiene 'inplace=True' por defecto) para bloquear el orden de un determinado nivel de MultiIndex promoviendo el nivel a 'CategoricalIndex':\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_128.png\">\n",
    "\n",
    "La marca de verificación '✓' junto al nombre de un nivel significa que el nivel está bloqueado. Se puede visualizar de forma manual con 'pdi.vis(df)' o de forma automática aplicando un parche a la representación HTML del marco de fecha con 'pdi.vis_patch()'. Después de aplicar el parche, simplemente escribiendo \"df\" en una celda de Jupyter se mostrarán las marcas de verificación de todos los niveles con ordenamiento bloqueado.\n",
    "\n",
    "'lock' y 'locked' funcionan automáticamente en casos simples (como nombres de clientes), pero necesitan una pista del usuario para los casos más complejos (como días de la semana con días faltantes).\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_129.png\">\n",
    "\n",
    "Una vez que se cambia el nivel a ''CategoricalIndex', mantiene el orden original en operaciones como 'sort_index', 'stack', 'unstack', 'pivot, 'pivot_table', etc.\n",
    "\n",
    "Sin embargo, es frágil. Incluso una operación tan inocente como agregar una columna a través de 'df[‘new_col’] = 1' la misma la rompe. Utilice 'pdi.insert(df.columns, 0, ‘new_col’, 1)' qué nivel(es) de procesos son los 'CategoricalIndex' correctos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulando niveles (levels)\n",
    "\n",
    "Además de los métodos ya mencionados, existen algunos más:\n",
    "\n",
    "- 'pdi.get_level' (obj, level_id) devuelve un nivel particular referenciado por número o por nombre, funciona con 'DataFrames', 'Series' y 'MultiIndex', un alias para 'df.columns.get_level_values';\n",
    "\n",
    "- 'pdi.set_level' (obj, level_id, labels) reemplaza las etiquetas de un nivel con la matriz dada ('lista', 'arrays', 'NumPy', 'Serie', 'Índice', etc.), — no tiene equivalente directo en  puro Pandas:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_130.png\">\n",
    "\n",
    "- 'pdi.insert_level' (obj, pos, labels, name) agrega un nivel con los valores dados (transmitidos correctamente si es necesario), — no se puede hacer fácilmente en puro Pandas;\n",
    "\n",
    "- 'pdi.drop_level' (obj, level_id) elimina el nivel especificado del 'MultiIndex' (agrega inplaceargumento a 'df.droplevel'):\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_131.png\">\n",
    "\n",
    "- 'pdi.swap_levels' (obj, src=-2, dst=-1) intercambia dos niveles (dos niveles más internos por defecto), agrega argumentos 'inplace' y 'sort' a 'df.swaplevel'\n",
    "\n",
    "- 'pdi.move_level'  (obj, src, dst) mueve un nivel particular srca la posición designada 'dst'(no se puede hacer fácilmente en puro Pandas):\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_132.png\">\n",
    "\n",
    "Además de los argumentos mencionados anteriormente, todas las funciones de esta sección tienen los siguientes argumentos:\n",
    "\n",
    "- 'axis=None' donde 'None' significa 'columnas' para un DataFrame e 'índice' para una Serie (también conocido como eje 'información');\n",
    "\n",
    "- 'sort=False', opcionalmente ordena el 'MultiIndex' correspondiente después de las manipulaciones;\n",
    "\n",
    "- 'inplace=False', opcionalmente realiza la manipulación en el lugar (no funciona con un solo Indexporque es inmutable).\n",
    "\n",
    "Todas las operaciones anteriores entienden la palabra nivel en el sentido convencional ( nivel tiene el mismo número de etiquetas que el número de columnas en el DataFrame), ocultando la maquinaria de 'index'.label' y 'index.codes' al usuario final.\n",
    "\n",
    "En las raras ocasiones en que mover e intercambiar niveles separados no es suficiente, puedes reordenar todos los niveles a la vez con esta llamada pura de Pandas:\n",
    "\n",
    "'df.columns = df.columns.reorder_levels(['M','L','K'])'\n",
    "donde ['M', 'L', 'K'] es el orden deseado de los niveles.\n",
    "\n",
    "Generalmente, es suficiente usar 'get_level' y ''set_level' hacer las correcciones necesarias a las etiquetas, pero si desea aplicar una transformación a todos los niveles del 'MultiIndex' a la vez, Pandas tiene una función (con nombre ambiguo) 'rename' que acepta un 'dict' o una función:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_133.png\">\n",
    "\n",
    "En cuanto al cambio de nombre de los niveles, sus nombres se almacenan en el campo '.names'. Este campo no admite asignaciones directas (¿por qué no?): pero se puede reemplazar como un todo: Alternativamente, puede utilizar un : encadenable\n",
    "\n",
    "'df.index.names[1] = ‘x’ ' # TypeError\n",
    "\n",
    "'df.index.names = ['z', 'x']' # ok\n",
    "\n",
    "rename_axis\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_134.png\">\n",
    "\n",
    "Cuando solo necesitas cambiar el nombre de un nivel en particular, la sintaxis es la siguiente:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_135.png\">\n",
    "\n",
    "O si desea hacer referencia al nivel por número en lugar de por nombre, utilice o (ambos también pueden funcionar por nombre).\n",
    "\n",
    "'df.index = df.index.set_names(‘z’, level=0)'\n",
    "\n",
    "'pdi.rename_level(df, 'z', 0, axis=0)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convertir MultiIndex en un índice plano y restaurarlo\n",
    "\n",
    "Como hemos visto anteriormente, el método 'query' conveniente solo resuelve la complejidad de trabajar con 'MultiIndex' en las filas. Y a pesar de todas las funciones auxiliares, cuando alguna función complicada de Pandas devuelve un 'MultiIndex' en las columnas, tiene un efecto de 'shock' para los principiantes. Por lo tanto, la biblioteca pdi tiene lo siguiente:\n",
    "\n",
    "- 'join_levels (obj, sep=’_’, name=None) Une todos los niveles de MultiIndex en un solo índice\n",
    "\n",
    "- 'split_level' (obj, sep=’_’, names=None)Divide el índice nuevamente en un Multiíndice\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_136.png\">\n",
    "\n",
    "Ambos tienen argumentos opcionales 'axis' y  'inplace'.\n",
    "\n",
    "En cuanto a una solución pura Pandas el siguiente código puede funcionar:\n",
    "\n",
    "- niveles de unión:\n",
    "\n",
    "'df.columns = ['_'.join(k) for k in df.columns.to_flat_index()]'\n",
    "\n",
    "- niveles divididos:\n",
    "\n",
    "'df.columns = pd.MultiIndex.from_tuples(k.split('_') for k in df.columns)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordenación de MultiIndex\n",
    "\n",
    "Dado que MultiIndex consta de varios niveles, la ordenación es un poco más complicada que para un único índice. Se puede hacer con el sort_indexmétodo, pero se puede ajustar aún más con los siguientes argumentos:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_137.png\">\n",
    "\n",
    "Para ordenar los niveles de columna, especifique 'axis=1'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lectura y escritura de marcos de datos multiindexados en el disco\n",
    "\n",
    "Pandas puede escribir un 'DataFrame' con un 'MultiIndex' en un archivo CSV de forma totalmente automática: 'df.to_csv('df.csv’)'. Sin embargo, al leer un archivo de este tipo, Pandas no puede analizar el 'MultiIndex' automáticamente y necesita algunas sugerencias del usuario. Por ejemplo, para leer un ''DataFrame' con columnas de tres niveles de alto y un índice de cuatro niveles de ancho, debe especificar\n",
    "\n",
    "'pd.read_csv('df.csv', header=[0,1,2], index_col=[0,1,2,3])'.\n",
    "\n",
    "Esto significa que las primeras tres líneas contienen la información sobre las columnas, y los primeros cuatro campos en cada una de las líneas subsiguientes contienen los niveles de índice (si hay más de un nivel en columns, no puede hacer referencia a los niveles de fila por nombres en read_csv, solo por números).\n",
    "\n",
    "No es conveniente descifrar manualmente el número de niveles en la columna 'MultiIndex', por lo que una mejor idea sería descifrar 'stack()' todos los niveles del encabezado de columna menos uno antes de guardar el 'DataFrame' en CSV, y 'unstack()' volver a descifrarlos después de leerlos.\n",
    "\n",
    "Si necesita una solución que se ejecute y se olvide, es posible que desee considerar los formatos binarios, como el formato 'pickle' de 'Python':\n",
    "\n",
    "- directamente: 'df.to_pickle('df.pkl'), pd.read_pickle('df.pkl')'\n",
    "\n",
    "- usando 'storemagic' en 'Jupyter' '%store df' entonces (almacena en) '%store -r df'\n",
    "\n",
    "'$HOME/.ipython/profile_default/db/autorestore'\n",
    "\n",
    "Este formato es pequeño y rápido, pero solo se puede acceder a él desde Python. Si necesita interoperabilidad con otros ecosistemas, busque formatos más estándar, como el formato Excel (que requiere las mismas sugerencias que 'read_csv' para leer 'MultiIndex'). Aquí está el código:\n",
    "\n",
    "!pip install openpyxl \n",
    "df.to_excel( 'df.xlsx' ) \n",
    "df1 = pd.read_excel( 'df.xlsx' , encabezado=[ 0 , 1 , 2 ], índice_col=[ 0 , 1 , 2 , 3 ])\n",
    "\n",
    "El formato de archivo 'Parquet' admite DataFrame multiindexados sin ningún tipo de sugerencia (la única limitación es que todas las etiquetas de columna deben ser cadenas), produce archivos más pequeños y funciona más rápido (consulte un punto de referencia):\n",
    "\n",
    "df.to_parquet( 'df.parquet' ) \n",
    "df1 = pd.read_parquet( 'df.parquet' )\n",
    "\n",
    "La documentación oficial de 'Pandas' tiene una tabla que enumera los aproximadamente 20 formatos compatibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aritmética de MultiIndex\n",
    "\n",
    "En las operaciones en las que se utiliza un DatFrame multiindexado como un todo, se aplican las mismas reglas que para los DataFrame comunes (consulte la Parte 3). Sin embargo, trabajar con un subconjunto de celdas tiene algunas peculiaridades propias.\n",
    "\n",
    "Puede actualizar un subconjunto de columnas referenciadas a través de los niveles MultiIndex externos de manera tan sencilla como la siguiente:\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_138.png\">\n",
    "\n",
    "O si desea mantener intactos los datos originales,.\n",
    "\n",
    "'df1 = df.assign(population=df.population*10)'\n",
    "\n",
    "También puedes obtener fácilmente la densidad de población con\n",
    "\n",
    "'density=df.population/df.area'.\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_139.png\">\n",
    "\n",
    "Pero desafortunadamente, no puedes asignar el resultado al marco de datos original con 'df.assign'.\n",
    "\n",
    "Un enfoque es apilar todos los niveles irrelevantes del índice de columna en el índice de fila, realizar los cálculos necesarios y volver a desapilarlos (usarlo pdi.lockpara mantener el orden original de las columnas).\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_140.png\">\n",
    "\n",
    "Alternativamente, puedes utilizar 'pdi.assign':\n",
    "\n",
    "<img src=\"Img/Articulo_2_diag_141.png\">\n",
    "\n",
    "'pdi.assign' es consciente del orden de bloqueo, por lo que si le suministra un 'DataFrame' con niveles bloqueados, no los desbloqueará para que las operaciones de apilado/desapilado/etc. posteriores mantengan las columnas y filas originales en orden.\n",
    "\n",
    "Un excelente ejemplo de procesamiento de un conjunto de datos de ventas de la vida real con un MultiIndex enorme se puede encontrar aquí.\n",
    "\n",
    "En definitiva, 'Pandas' es una gran herramienta para analizar y procesar datos. Esperamos que este artículo te haya ayudado a entender tanto el \"cómo\" como el \"por qué\" de la solución de problemas típicos, y a apreciar el verdadero valor y la belleza de la biblioteca Pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
